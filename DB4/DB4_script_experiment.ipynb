{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c52a439-a7c9-48a9-8271-b4058f00b6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:25:07.321617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 13:25:07.566760: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 13:25:08.289908: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-11-27 13:25:08.289973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-11-27 13:25:08.289976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Keras: 2.11.0\n",
      "Tensorflow: 2.11.0\n",
      "Logging file: /home/sota/EMGcode/EMG_experiment/Result/L_TCCNet_att.log\n",
      "Tensorboard file: /home/sota/EMGcode/EMG_experiment/Result/tblogs/L_TCCNet_att\n",
      "Model JSON file: /home/sota/EMGcode/EMG_experiment/Result/models/O1_TCCNet_att_{}.json\n",
      "Model H5 file: /home/sota/EMGcode/EMG_experiment/Result/models/O2_TCCNet_att_{}.h5\n",
      "Metrics file: /home/sota/EMGcode/EMG_experiment/Result/metrics/O3_TCCNet_att_{}.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:25:09.887571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:10.085271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:10.087601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:10.090466: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 13:25:10.092301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:10.093685: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:10.095093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:10.452112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:10.453896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:10.454960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:10.455930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20713 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import sys, os\n",
    "sys.path.append('/home/sota/EMGcode/EMG_experiment/')\n",
    "import mypreprocessing\n",
    "from generator2 import DataGenerator\n",
    "from models import getNetwork\n",
    "from custom_layers import MeanOverTime\n",
    "import sys, os\n",
    "import json\n",
    "import scipy\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import optimizers, initializers, regularizers, constraints\n",
    "from utils import *\n",
    "from sklearn import metrics\n",
    "import matplotlib as plt\n",
    "from keras.layers import *\n",
    "from tcn import TCN\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyp\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "folder_process_data = '/home/sota/EMGcode/EMG_experiment/DB4_pre/'\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "print('Keras:', keras.__version__)\n",
    "print('Tensorflow:', tf.__version__)\n",
    "\n",
    "# 1. Logging\n",
    "'''\n",
    "if len(sys.argv) == 4:\n",
    "    CONFIG_FILE = str(sys.argv[1])\n",
    "    SUBJECT = int(sys.argv[2])\n",
    "    TIMESTAMP = int(sys.argv[3])\n",
    "else:\n",
    "    print('Expected different number of arguments. {} were given'.format(len(sys.argv) - 1))\n",
    "    sys.exit()\n",
    "    '''\n",
    "CONFIG_FILE='/home/sota/EMGcode/EMG_experiment/config/TCCNet_aot_2 (1).json'\n",
    "\n",
    "SUBJECT=1\n",
    "GESTURES=52\n",
    "\n",
    "with open(CONFIG_FILE) as json_file:\n",
    "    config_params = json.load(json_file)\n",
    "outdir='/home/sota/EMGcode/EMG_experiment/DB9_pre/Result'\n",
    "LOGGING_FILE_PREFIX = config_params['logging']['log_file']\n",
    "if config_params['logging']['enable']:\n",
    "    LOGGING_FILE = '/home/sota/EMGcode/EMG_experiment/Result/L_' + LOGGING_FILE_PREFIX + '.log'# 'Musa_NinaPro_Project/ProcessedData/DB1/Result/L_' + LOGGING_FILE_PREFIX + '.log'\n",
    "    LOGGING_TENSORBOARD_FILE = '/home/sota/EMGcode/EMG_experiment/Result/tblogs/L_' + LOGGING_FILE_PREFIX #'Musa_NinaPro_Project/ProcessedData/DB1/Result/tblogs/L_' + LOGGING_FILE_PREFIX\n",
    "\n",
    "if config_params['model']['save']:\n",
    "    MODEL_SAVE_FILE = '/home/sota/EMGcode/EMG_experiment/Result/models/O1_' + LOGGING_FILE_PREFIX + '_{}.json'\n",
    "    MODEL_WEIGHTS_SAVE_FILE = '/home/sota/EMGcode/EMG_experiment/Result/models/O2_' + LOGGING_FILE_PREFIX + '_{}.h5'\n",
    "\n",
    "METRICS_SAVE_FILE = '/home/sota/EMGcode/EMG_experiment/Result/metrics/O3_' + LOGGING_FILE_PREFIX + '_{}.mat'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(METRICS_SAVE_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(METRICS_SAVE_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "if not os.path.exists(os.path.dirname(MODEL_SAVE_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(MODEL_SAVE_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "if not os.path.exists(os.path.dirname(LOGGING_TENSORBOARD_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(LOGGING_TENSORBOARD_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "print('Logging file: {}'.format(LOGGING_FILE))\n",
    "print('Tensorboard file: {}'.format(LOGGING_TENSORBOARD_FILE))\n",
    "print('Model JSON file: {}'.format(MODEL_SAVE_FILE))\n",
    "print('Model H5 file: {}'.format(MODEL_WEIGHTS_SAVE_FILE))\n",
    "print('Metrics file: {}'.format(METRICS_SAVE_FILE))\n",
    "\n",
    "# 2. Config params generator\n",
    "PARAMS_TRAIN_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('train_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_TRAIN_GENERATOR[key] = params_gen[key]\n",
    "\n",
    "PARAMS_VALID_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('valid_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_VALID_GENERATOR[key] = params_gen[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "941b9616-794a-4be5-b1a6-37f33ee50999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K, regularizers, constraints, initializers\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"アテンションの重みの計算\n",
    "  q, k, vは最初の次元が一致していること\n",
    "  k, vは最後から2番めの次元が一致していること\n",
    "  マスクは型（パディングかルックアヘッドか）によって異なるshapeを持つが、\n",
    "  加算の際にブロードキャスト可能であること\n",
    "  引数：\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: (..., seq_len_q, seq_len_k) にブロードキャスト可能な\n",
    "          shapeを持つ浮動小数点テンソル。既定値はNone\n",
    "\n",
    "  戻り値：\n",
    "    出力、アテンションの重み\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # matmul_qkをスケール\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # マスクをスケール済みテンソルに加算\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # softmax は最後の軸(seq_len_k)について\n",
    "  # 合計が1となるように正規化\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights\n",
    "\n",
    "class ChannelAttention(Layer):\n",
    "    def __init__(self, ratio = 8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=self.channels // self.ratio,\n",
    "                                           activation='relu',\n",
    "                                           kernel_initializer='he_normal',\n",
    "                                           use_bias=True)\n",
    "        self.dense_output = tf.keras.layers.Dense(units=self.channels,\n",
    "                                                  kernel_initializer='he_normal',\n",
    "                                                  use_bias=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs = tf.expand_dims(inputs, axis=2)\n",
    "        gap = tf.reduce_mean(inputs, axis=[0, 1], keepdims=True)\n",
    "\n",
    "        attention = self.dense(gap)\n",
    "        attention = self.dense_output(attention)\n",
    "        attention = tf.keras.activations.sigmoid(attention)\n",
    "\n",
    "        output = tf.multiply(inputs, attention)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5b0bee-3d02-4764-aa70-3630a4390c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_subject = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ddf331e-0b9e-4637-8491-0db1a3ba1380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:25:13.229409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.230977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.232512: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.233941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.235397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.236825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20713 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-11-27 13:25:13.238684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.240682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.242128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.243528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.244946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-27 13:25:13.246006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20713 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 4\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 232\u001b[0m\n\u001b[1;32m    229\u001b[0m input_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/subject-\u001b[39m\u001b[38;5;132;01m{:02d}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(INPUT_DIRECTORY, target_subject)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# print(input_dir)\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mDataGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mPARAMS_TRAIN_GENERATOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m valid_generator \u001b[38;5;241m=\u001b[39m DataGenerator(input_directory\u001b[38;5;241m=\u001b[39minput_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mPARAMS_VALID_GENERATOR)\n\u001b[1;32m    235\u001b[0m X_train, Y_train, train_reps,L_\u001b[38;5;241m=\u001b[39mtrain_generator\u001b[38;5;241m.\u001b[39mget_data()\n",
      "File \u001b[0;32m~/EMGcode/EMG_experiment/generator2.py:82\u001b[0m, in \u001b[0;36mDataGenerator.__init__\u001b[0;34m(self, repetitions, input_directory, batch_size, sample_weight, dim, classes, shuffle, noise_snr_db, scale_sigma, window_size, window_step, rotation, rotation_mask, time_warping, mag_warping, permutation, data_type, preprocess_function_1, preprocess_function_2, preprocess_function_1_extra, preprocess_function_2_extra, size_factor, pad_len, pad_value, min_max_norm, update_after_epoch, label_proc, label_proc_extra)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_proc \u001b[38;5;241m=\u001b[39m label_proc  \u001b[38;5;66;03m#none\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_proc_extra \u001b[38;5;241m=\u001b[39m label_proc_extra  \u001b[38;5;66;03m#none\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__validate_params()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__generate()\n",
      "File \u001b[0;32m~/EMGcode/EMG_experiment/generator2.py:254\u001b[0m, in \u001b[0;36mDataGenerator.__load_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[1;32m    253\u001b[0m         X\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m--> 254\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstimulus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m    255\u001b[0m         r\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqueeze(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepetition\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "os.chdir('/home/sota/EMGcode/EMG_experiment/')\n",
    "import mypreprocessing\n",
    "from generator2 import DataGenerator\n",
    "#from models import getNetwork\n",
    "from DB2_Mydataset import *\n",
    "#from model.ninapro_network import *\n",
    "#from models import TCCNet\n",
    "from models import getNetwork\n",
    "import sys\n",
    "import json\n",
    "import scipy\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import optimizers, initializers, regularizers, constraints\n",
    "from utils import *\n",
    "from sklearn import metrics\n",
    "# print(DEFAULT_GENERATOR_PARAMS)\n",
    "os.getcwd()\n",
    "\n",
    "import argparse\n",
    "#import torch\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# parser.add_argument(\"-b\", \"--batch_size\", type=int, default=128)  # 16\n",
    "# parser.add_argument(\"-lr\", \"--learning_rate\", type=float, default=1e-3)\n",
    "# parser.add_argument('--cuda', default=True, help='enables cuda')\n",
    "# parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',\n",
    "#                     help='number of data loading workers (default: 8)')\n",
    "# parser.add_argument('--epochs', default=1000, type=int, metavar='N',\n",
    "#                     help='number of total epochs to run')  # 1000\n",
    "\n",
    "# parser.add_argument('--patiences', default=500, type=int,\n",
    "#                     help='number of epochs to tolerate no improvement of val_loss')  # 1000\n",
    "\n",
    "# '''\n",
    "# parser.add_argument('--test_subject_id', type=int, default=3,\n",
    "#                     help='id of test subject, for cross-validation')\n",
    "\n",
    "# parser.add_argument('--data_cfg', type=int, default=1,\n",
    "#                     help='0 for 14 class, 1 for 28')\n",
    "\n",
    "# '''\n",
    "# parser.add_argument('--dp_rate', type=float, default=0.1,\n",
    "#                     help='dropout rate')  # 1000\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/keras-team/keras/issues/2280#issuecomment-306959926\n",
    "folder_process_data = '/home/sota/EMGcode/EMG_experiment/DB4_pre'\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(1234)\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "random.seed(12345)\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see:\n",
    "#    https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=0,\n",
    "    inter_op_parallelism_threads=0\n",
    ")\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "#   https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "tf.random.set_seed(1234)\n",
    "#tf.compat.v1.Session()\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# 1. Logging\n",
    "'''\n",
    "if len(sys.argv) == 4:\n",
    "    CONFIG_FILE = str(sys.argv[1])\n",
    "    SUBJECT = int(sys.argv[2])\n",
    "    TIMESTAMP = int(sys.argv[3])\n",
    "else:\n",
    "    print('Expected different number of arguments. {} were given'.format(len(sys.argv) - 1))\n",
    "    sys.exit()\n",
    "    '''\n",
    "CONFIG_FILE='/home/sota/EMGcode/EMG_experiment/config/TCCNet_aot_2 (1).json'\n",
    "\n",
    "SUBJECT=1\n",
    "GESTURES=52\n",
    "\n",
    "\n",
    "with open(CONFIG_FILE) as json_file:\n",
    "    config_params = json.load(json_file)\n",
    "outdir='/home/sota/EMGcode/EMG_experiment/DB9_pre/Result'\n",
    "LOGGING_FILE_PREFIX = config_params['logging']['log_file']\n",
    "if config_params['logging']['enable']:\n",
    "    LOGGING_FILE = '/home/sota/EMGcode/EMG_experiment/Result/L_' + LOGGING_FILE_PREFIX + '.log'# 'Musa_NinaPro_Project/ProcessedData/DB1/Result/L_' + LOGGING_FILE_PREFIX + '.log'\n",
    "    LOGGING_TENSORBOARD_FILE = '/home/sota/EMGcode/EMG_experiment/Result/tblogs/L_' + LOGGING_FILE_PREFIX #'Musa_NinaPro_Project/ProcessedData/DB1/Result/tblogs/L_' + LOGGING_FILE_PREFIX\n",
    "\n",
    "if config_params['model']['save']:\n",
    "    MODEL_SAVE_FILE = '/home/sota/EMGcode/EMG_experiment/Result/models/O1_' + LOGGING_FILE_PREFIX + '_{}.json'\n",
    "    MODEL_WEIGHTS_SAVE_FILE = '/home/sota/EMGcode/EMG_experiment/Result/models/O2_' + LOGGING_FILE_PREFIX + '_{}.h5'\n",
    "\n",
    "METRICS_SAVE_FILE = '/home/sota/EMGcode/EMG_experiment/Result/metrics/O3_' + LOGGING_FILE_PREFIX + '_{}.mat'\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.dirname(METRICS_SAVE_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(METRICS_SAVE_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "if not os.path.exists(os.path.dirname(MODEL_SAVE_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(MODEL_SAVE_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "if not os.path.exists(os.path.dirname(LOGGING_TENSORBOARD_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(LOGGING_TENSORBOARD_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "# 2. Config params generator\n",
    "PARAMS_TRAIN_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('train_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_TRAIN_GENERATOR[key] = params_gen[key]\n",
    "# print(PARAMS_TRAIN_GENERATOR)\n",
    "PARAMS_VALID_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('valid_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_VALID_GENERATOR[key] = params_gen[key]\n",
    "\n",
    "# 3. Initialization\n",
    "#INPUT_DIRECTORY = '../dataset/Ninapro-DB1-Proc'\n",
    "INPUT_DIRECTORY = folder_process_data        #link of process dataset\n",
    "PARAMS_TRAIN_GENERATOR['preprocess_function_1'] = [mypreprocessing.lpf]\n",
    "PARAMS_TRAIN_GENERATOR['preprocess_function_1_extra'] = [{'fs': 100}]\n",
    "PARAMS_TRAIN_GENERATOR['data_type'] = 'rms'\n",
    "PARAMS_TRAIN_GENERATOR['classes'] = [i for i in range(1, 53)]\n",
    "PARAMS_TRAIN_GENERATOR['dim'] = [None,12]\n",
    "PARAMS_TRAIN_GENERATOR['repetitions'] = [1, 3, 4, 6]\n",
    "PARAMS_TRAIN_GENERATOR['size_factor'] = 10\n",
    "# PARAMS_TRAIN_GENERATOR['min_max_norm'] = True\n",
    "\n",
    "PARAMS_VALID_GENERATOR['preprocess_function_1'] = [mypreprocessing.lpf]\n",
    "PARAMS_VALID_GENERATOR['preprocess_function_1_extra'] = [{'fs': 100}]\n",
    "PARAMS_VALID_GENERATOR['data_type'] = 'rms'\n",
    "PARAMS_VALID_GENERATOR['classes'] = [i for i in range(1, 53)]\n",
    "PARAMS_VALID_GENERATOR['dim'] = [None,12]\n",
    "PARAMS_VALID_GENERATOR['repetitions'] = [2,5]\n",
    "PARAMS_VALID_GENERATOR['size_factor'] = 10\n",
    "# PARAMS_VALID_GENERATOR['min_max_norm'] = True\n",
    "\n",
    "# PARAMS_TRAIN_GENERATOR['batch_size'] = int(8)\n",
    "# PARAMS_VALID_GENERATOR['batch_size'] = int(1)\n",
    "PARAMS_TRAIN_GENERATOR['batch_size'] = int(128/4)\n",
    "PARAMS_VALID_GENERATOR['batch_size'] = int(128/4)\n",
    "learning_late = config_params['training']['l_rate']\n",
    "\n",
    "# PARAMS_TRAIN_GENERATOR['window_size'] = 1000\n",
    "# PARAMS_VALID_GENERATOR['window_size'] = 1000\n",
    "\n",
    "# PARAMS_TRAIN_GENERATOR['window_step'] = 500\n",
    "# PARAMS_VALID_GENERATOR['window_step'] = 500\n",
    "\n",
    "SUBJECTS = config_params['dataset'].get('subjects', [i for i in range(1, 11)])\n",
    "if np.min(SUBJECTS) <= 0 or np.max(SUBJECTS) >= 11:\n",
    "    raise AssertionError('Subject IDs should be between 1 and 27 inclusive for DB1. Were given {}\\n'.format(SUBJECTS))\n",
    "\n",
    "PARAMS_TRAIN_GENERATOR.pop('input_directory', '')\n",
    "PARAMS_VALID_GENERATOR.pop('input_directory', '')\n",
    "\n",
    "\n",
    "#MODEL = getNetwork(config_params['model']['name'])\n",
    "\n",
    "mean_train, mean_test, mean_test_3, mean_test_5 = [], [], [], []\n",
    "mean_cm = []\n",
    "mean_train_loss, mean_test_loss = [], []\n",
    "\n",
    "if config_params['logging']['enable']:\n",
    "    if os.path.isfile(LOGGING_FILE) == False:\n",
    "        with open(LOGGING_FILE, 'w') as f:\n",
    "            f.write(\n",
    "                'TIMESTAMP: {}\\n'\n",
    "                'KERAS: {}\\n'\n",
    "                'TENSORFLOW: {}\\n'\n",
    "                'DATASET: {}\\n'\n",
    "                'TRAIN_GENERATOR: {}\\n'\n",
    "                'VALID_GENERATOR: {}\\n'\n",
    "                'MODEL: {}\\n'\n",
    "                'MODEL_PARAMS: {}\\n'\n",
    "                'TRAIN_PARAMS: {}\\n'.format(\n",
    "                    keras.__version__, tf.__version__,\n",
    "                    config_params['dataset']['name'], PARAMS_TRAIN_GENERATOR,\n",
    "                    PARAMS_VALID_GENERATOR,\n",
    "                    config_params['model']['name'], config_params['model']['extra'],\n",
    "                    config_params['training']\n",
    "                )\n",
    "            )\n",
    "            f.write(\n",
    "                'SUBJECT,TRAIN_SHAPE,TEST_SHAPE,TRAIN_LOSS,TRAIN_ACC,TEST_LOSS,TEST_ACC,TEST_TOP_3_ACC,TEST_TOP_5_ACC\\n')\n",
    "\n",
    "print(f'Subject: {target_subject}')\n",
    "input_dir = '{}/subject-{:02d}'.format(INPUT_DIRECTORY, target_subject)\n",
    "# print(input_dir)\n",
    "\n",
    "train_generator = DataGenerator(input_directory=input_dir, **PARAMS_TRAIN_GENERATOR)\n",
    "valid_generator = DataGenerator(input_directory=input_dir, **PARAMS_VALID_GENERATOR)\n",
    "\n",
    "X_train, Y_train, train_reps,L_=train_generator.get_data()\n",
    "# print(X_train[1].shape)   # X_train_shape=   2176*14221*12\n",
    "# print(Y_train.shape)   #Y_train_shape= 2176*50\n",
    "# print(Y_train)\n",
    "# print(L_.shape)\n",
    "# print(L_)\n",
    "\n",
    "y_train=np.where(Y_train==1)[1]\n",
    "# print(y_train.shape)\n",
    "\n",
    "X_test, Y_test, test_reps = valid_generator.get_data()     \n",
    "                             # X test,  Y test\n",
    "# print(X_test.shape)  #shape   X=100*13083, 12  it is for 2 reptation  Y=100*50   \n",
    "# print(Y_test.shape)\n",
    "y_test=np.where(Y_test==1)[1]\n",
    "\n",
    "# print(y_test.shape)\n",
    "\n",
    "#reshape of x_train    reading*sample*channel*1\n",
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "\n",
    "# print(X_train.shape[0])\n",
    "train_dataset = Hand_Dataset(X_train, y_train)   # for 1*8*22*3  label=1\n",
    "# print(train_dataset[1]['skeleton'].shape)\n",
    "    \n",
    "# print('Call Mydataset for testing :')\n",
    "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    "test_dataset =  Hand_Dataset(X_test, y_test)\n",
    "# print(test_dataset[1]['skeleton'].shape)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# args, unknown = parser.parse_known_args()\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=args.batch_size, shuffle=True,\n",
    "#     num_workers=args.workers, pin_memory=False)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     test_dataset,\n",
    "#     batch_size=args.batch_size, shuffle=False,\n",
    "#     num_workers=args.workers, pin_memory=False)\n",
    "\n",
    "class_num=train_generator.n_classes\n",
    "# print(class_num)\n",
    "\n",
    "timelen=X_train.shape[1]\n",
    "\n",
    "# print(timelen)\n",
    "\n",
    "# print('Train generator:')\n",
    "# print(train_generator)\n",
    "# print('Test generator:')\n",
    "# print(valid_generator)\n",
    "# print(train_generator.n_classes)\n",
    "# print(train_generator.repetitions)\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0341710-1470-4334-b24e-62e4b7abcb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 12)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, None, 2)      74          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " separable_conv1d (SeparableCon  (None, None, 2)     12          ['conv1d[0][0]']                 \n",
      " v1D)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 2)           0           ['separable_conv1d[0][0]']       \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 0)            0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tcn (TCN)                      (None, None, 32)     35744       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            2           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, None, 64)     16640       ['tcn[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, None, 2)      0           ['separable_conv1d[0][0]',       \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, None, 64)    71488       ['input_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 64)          0           ['bidirectional[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 2)           0           ['multiply[0][0]']               \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 64)          0           ['bidirectional_1[0][0]']        \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 130)          0           ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 130)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " channel_attention (ChannelAtte  (None, 130)         2242        ['dropout[0][0]']                \n",
      " ntion)                                                                                           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 52)           6812        ['channel_attention[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 133,014\n",
      "Trainable params: 133,014\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from tcn import TCN\n",
    "from keras.models import Model\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "def se_block(in_block, ch, ratio=2):\n",
    "    z = GlobalAveragePooling1D()(in_block) \n",
    "    x = Dense(ch // ratio, activation='relu')(z)\n",
    "    x = Dense(ch, activation='sigmoid')(x)\n",
    "    return multiply([in_block, x])\n",
    "\n",
    "input_shape = (None, 12)\n",
    "\n",
    "input = Input(shape=input_shape)\n",
    "\n",
    "branch1 = TCN(nb_filters=32, nb_stacks=1, kernel_size=3, return_sequences=True)(input)\n",
    "branch1 = Bidirectional(LSTM(32, return_sequences=True))(branch1)\n",
    "\n",
    "branch2 = Conv1D(2, 3)(input)\n",
    "branch2 = SeparableConv1D(filters=2, kernel_size=3, padding='same', activation='relu')(branch2)\n",
    "branch2 = se_block(branch2, ch=2)\n",
    "\n",
    "branch3 = Bidirectional(TCN(nb_filters=32, nb_stacks=1, kernel_size=3, return_sequences=True))(input)\n",
    "\n",
    "# Flatten the sequences before concatenating\n",
    "branch1_flat = GlobalAveragePooling1D()(branch1)\n",
    "branch2_flat = GlobalAveragePooling1D()(branch2)\n",
    "branch3_flat = GlobalAveragePooling1D()(branch3)\n",
    "# input_flat = GlobalAveragePooling1D()(input)\n",
    "\n",
    "x = concatenate([branch1_flat, branch2_flat, branch3_flat])\n",
    "# x = concatenate([branch1_flat, branch2_flat, branch3_flat, input_flat])\n",
    "x = Dropout(0.2)(x)\n",
    "x = ChannelAttention()(x)\n",
    "output = Dense(52, trainable=True, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3266127-2601-4a9a-8e76-b84d13a4f208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 16:09:13.632266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2024-11-19 16:09:13.681254: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-11-19 16:09:14.034082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 1: saved predictions and true labels\n",
      "71/71 - 33s - loss: 5.5215 - accuracy: 0.0268 - top_3_accuracy: 0.0726 - top_5_accuracy: 0.1276 - val_loss: 3.8677 - val_accuracy: 0.0521 - val_top_3_accuracy: 0.1042 - val_top_5_accuracy: 0.1979 - 33s/epoch - 466ms/step\n",
      "Epoch 2/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 2: saved predictions and true labels\n",
      "71/71 - 27s - loss: 3.7566 - accuracy: 0.0511 - top_3_accuracy: 0.1501 - top_5_accuracy: 0.2262 - val_loss: 3.5002 - val_accuracy: 0.1146 - val_top_3_accuracy: 0.2396 - val_top_5_accuracy: 0.2917 - 27s/epoch - 387ms/step\n",
      "Epoch 3/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 3: saved predictions and true labels\n",
      "71/71 - 27s - loss: 3.2101 - accuracy: 0.1351 - top_3_accuracy: 0.3116 - top_5_accuracy: 0.4199 - val_loss: 2.6052 - val_accuracy: 0.2396 - val_top_3_accuracy: 0.5312 - val_top_5_accuracy: 0.6979 - 27s/epoch - 387ms/step\n",
      "Epoch 4/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 4: saved predictions and true labels\n",
      "71/71 - 27s - loss: 2.4946 - accuracy: 0.2702 - top_3_accuracy: 0.5119 - top_5_accuracy: 0.6461 - val_loss: 1.9189 - val_accuracy: 0.4688 - val_top_3_accuracy: 0.7396 - val_top_5_accuracy: 0.8542 - 27s/epoch - 387ms/step\n",
      "Epoch 5/128\n",
      "3/3 [==============================] - 1s 176ms/step\n",
      "Epoch 5: saved predictions and true labels\n",
      "71/71 - 27s - loss: 1.9835 - accuracy: 0.3803 - top_3_accuracy: 0.6717 - top_5_accuracy: 0.7971 - val_loss: 1.4765 - val_accuracy: 0.5833 - val_top_3_accuracy: 0.7708 - val_top_5_accuracy: 0.9167 - 27s/epoch - 387ms/step\n",
      "Epoch 6/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 6: saved predictions and true labels\n",
      "71/71 - 27s - loss: 1.7334 - accuracy: 0.4586 - top_3_accuracy: 0.7236 - top_5_accuracy: 0.8473 - val_loss: 1.4128 - val_accuracy: 0.6042 - val_top_3_accuracy: 0.8229 - val_top_5_accuracy: 0.9271 - 27s/epoch - 386ms/step\n",
      "Epoch 7/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 7: saved predictions and true labels\n",
      "71/71 - 27s - loss: 1.5881 - accuracy: 0.4987 - top_3_accuracy: 0.7790 - top_5_accuracy: 0.8754 - val_loss: 1.1656 - val_accuracy: 0.6146 - val_top_3_accuracy: 0.8750 - val_top_5_accuracy: 0.9583 - 27s/epoch - 387ms/step\n",
      "Epoch 8/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 8: saved predictions and true labels\n",
      "71/71 - 27s - loss: 1.4128 - accuracy: 0.5383 - top_3_accuracy: 0.8261 - top_5_accuracy: 0.9045 - val_loss: 1.0074 - val_accuracy: 0.6875 - val_top_3_accuracy: 0.9062 - val_top_5_accuracy: 0.9688 - 27s/epoch - 386ms/step\n",
      "Epoch 9/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 9: saved predictions and true labels\n",
      "71/71 - 27s - loss: 1.2912 - accuracy: 0.5766 - top_3_accuracy: 0.8468 - top_5_accuracy: 0.9221 - val_loss: 0.9940 - val_accuracy: 0.6667 - val_top_3_accuracy: 0.8958 - val_top_5_accuracy: 0.9479 - 27s/epoch - 386ms/step\n",
      "Epoch 10/128\n",
      "3/3 [==============================] - 1s 176ms/step\n",
      "Epoch 10: saved predictions and true labels\n",
      "71/71 - 27s - loss: 1.1580 - accuracy: 0.6188 - top_3_accuracy: 0.8746 - top_5_accuracy: 0.9476 - val_loss: 0.9631 - val_accuracy: 0.7083 - val_top_3_accuracy: 0.8854 - val_top_5_accuracy: 0.9688 - 27s/epoch - 386ms/step\n",
      "Epoch 11/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 11: saved predictions and true labels\n",
      "71/71 - 27s - loss: 1.1077 - accuracy: 0.6338 - top_3_accuracy: 0.8838 - top_5_accuracy: 0.9432 - val_loss: 0.9716 - val_accuracy: 0.6875 - val_top_3_accuracy: 0.9062 - val_top_5_accuracy: 0.9479 - 27s/epoch - 386ms/step\n",
      "Epoch 12/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 12: saved predictions and true labels\n",
      "71/71 - 27s - loss: 1.0521 - accuracy: 0.6607 - top_3_accuracy: 0.8856 - top_5_accuracy: 0.9551 - val_loss: 0.8273 - val_accuracy: 0.7604 - val_top_3_accuracy: 0.9062 - val_top_5_accuracy: 0.9792 - 27s/epoch - 387ms/step\n",
      "Epoch 13/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 13: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.9198 - accuracy: 0.6915 - top_3_accuracy: 0.9111 - top_5_accuracy: 0.9679 - val_loss: 0.8989 - val_accuracy: 0.7396 - val_top_3_accuracy: 0.9062 - val_top_5_accuracy: 0.9688 - 27s/epoch - 387ms/step\n",
      "Epoch 14/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 14: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.8947 - accuracy: 0.6963 - top_3_accuracy: 0.9208 - top_5_accuracy: 0.9674 - val_loss: 0.6573 - val_accuracy: 0.7708 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 15/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 15: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.8907 - accuracy: 0.7020 - top_3_accuracy: 0.9195 - top_5_accuracy: 0.9679 - val_loss: 0.6442 - val_accuracy: 0.7917 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 1.0000 - 27s/epoch - 387ms/step\n",
      "Epoch 16/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 16: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.7761 - accuracy: 0.7333 - top_3_accuracy: 0.9415 - top_5_accuracy: 0.9789 - val_loss: 0.7663 - val_accuracy: 0.7396 - val_top_3_accuracy: 0.9271 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 17/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 17: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.7502 - accuracy: 0.7509 - top_3_accuracy: 0.9463 - top_5_accuracy: 0.9798 - val_loss: 0.6879 - val_accuracy: 0.7812 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 18/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 18: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.7146 - accuracy: 0.7504 - top_3_accuracy: 0.9454 - top_5_accuracy: 0.9824 - val_loss: 0.6184 - val_accuracy: 0.8021 - val_top_3_accuracy: 0.9896 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 19/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 19: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.6901 - accuracy: 0.7597 - top_3_accuracy: 0.9463 - top_5_accuracy: 0.9820 - val_loss: 0.6907 - val_accuracy: 0.7917 - val_top_3_accuracy: 0.9375 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 20/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 20: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.7755 - accuracy: 0.7465 - top_3_accuracy: 0.9353 - top_5_accuracy: 0.9736 - val_loss: 0.6934 - val_accuracy: 0.7708 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 21/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 21: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.7319 - accuracy: 0.7500 - top_3_accuracy: 0.9410 - top_5_accuracy: 0.9780 - val_loss: 0.7372 - val_accuracy: 0.7292 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9792 - 27s/epoch - 385ms/step\n",
      "Epoch 22/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 22: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.6861 - accuracy: 0.7658 - top_3_accuracy: 0.9547 - top_5_accuracy: 0.9820 - val_loss: 0.5909 - val_accuracy: 0.8125 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 23/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 23: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.6543 - accuracy: 0.7768 - top_3_accuracy: 0.9591 - top_5_accuracy: 0.9850 - val_loss: 0.6160 - val_accuracy: 0.7812 - val_top_3_accuracy: 0.9375 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 24/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 24: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.6517 - accuracy: 0.7821 - top_3_accuracy: 0.9547 - top_5_accuracy: 0.9815 - val_loss: 0.6187 - val_accuracy: 0.8021 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 1.0000 - 27s/epoch - 387ms/step\n",
      "Epoch 25/128\n",
      "3/3 [==============================] - 1s 176ms/step\n",
      "Epoch 25: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.6062 - accuracy: 0.7975 - top_3_accuracy: 0.9577 - top_5_accuracy: 0.9850 - val_loss: 0.5015 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9896 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 26/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 26: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.5581 - accuracy: 0.8112 - top_3_accuracy: 0.9665 - top_5_accuracy: 0.9890 - val_loss: 0.5894 - val_accuracy: 0.8021 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 27/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 27: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.5726 - accuracy: 0.7967 - top_3_accuracy: 0.9573 - top_5_accuracy: 0.9855 - val_loss: 0.6558 - val_accuracy: 0.7812 - val_top_3_accuracy: 0.9375 - val_top_5_accuracy: 0.9688 - 27s/epoch - 386ms/step\n",
      "Epoch 28/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 28: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.7667 - accuracy: 0.7487 - top_3_accuracy: 0.9485 - top_5_accuracy: 0.9771 - val_loss: 0.5904 - val_accuracy: 0.7604 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 1.0000 - 27s/epoch - 385ms/step\n",
      "Epoch 29/128\n",
      "3/3 [==============================] - 1s 172ms/step\n",
      "Epoch 29: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.5707 - accuracy: 0.8024 - top_3_accuracy: 0.9688 - top_5_accuracy: 0.9894 - val_loss: 0.5637 - val_accuracy: 0.7604 - val_top_3_accuracy: 0.9167 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 30/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 30: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.5548 - accuracy: 0.8068 - top_3_accuracy: 0.9714 - top_5_accuracy: 0.9890 - val_loss: 0.5284 - val_accuracy: 0.8229 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 31/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 31: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.5131 - accuracy: 0.8187 - top_3_accuracy: 0.9696 - top_5_accuracy: 0.9921 - val_loss: 0.6627 - val_accuracy: 0.7812 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9688 - 27s/epoch - 386ms/step\n",
      "Epoch 32/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 32: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.5181 - accuracy: 0.8213 - top_3_accuracy: 0.9679 - top_5_accuracy: 0.9921 - val_loss: 0.5421 - val_accuracy: 0.8125 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 385ms/step\n",
      "Epoch 33/128\n",
      "3/3 [==============================] - 1s 172ms/step\n",
      "Epoch 33: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.5424 - accuracy: 0.8182 - top_3_accuracy: 0.9696 - top_5_accuracy: 0.9903 - val_loss: 0.4213 - val_accuracy: 0.8646 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 34/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 34: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4771 - accuracy: 0.8424 - top_3_accuracy: 0.9683 - top_5_accuracy: 0.9943 - val_loss: 0.5034 - val_accuracy: 0.8125 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 1.0000 - 27s/epoch - 385ms/step\n",
      "Epoch 35/128\n",
      "3/3 [==============================] - 1s 176ms/step\n",
      "Epoch 35: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.5075 - accuracy: 0.8305 - top_3_accuracy: 0.9701 - top_5_accuracy: 0.9912 - val_loss: 0.5768 - val_accuracy: 0.7917 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 36/128\n",
      "3/3 [==============================] - 1s 173ms/step\n",
      "Epoch 36: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4401 - accuracy: 0.8530 - top_3_accuracy: 0.9784 - top_5_accuracy: 0.9930 - val_loss: 0.4509 - val_accuracy: 0.8125 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 37/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 37: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4568 - accuracy: 0.8424 - top_3_accuracy: 0.9749 - top_5_accuracy: 0.9934 - val_loss: 0.5393 - val_accuracy: 0.8646 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 38/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 38: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4903 - accuracy: 0.8305 - top_3_accuracy: 0.9776 - top_5_accuracy: 0.9934 - val_loss: 0.5254 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 1.0000 - 27s/epoch - 387ms/step\n",
      "Epoch 39/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 39: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4806 - accuracy: 0.8389 - top_3_accuracy: 0.9784 - top_5_accuracy: 0.9934 - val_loss: 0.5501 - val_accuracy: 0.8229 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9688 - 27s/epoch - 386ms/step\n",
      "Epoch 40/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 40: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.3991 - accuracy: 0.8605 - top_3_accuracy: 0.9815 - top_5_accuracy: 0.9952 - val_loss: 0.5817 - val_accuracy: 0.7812 - val_top_3_accuracy: 0.9896 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 41/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 41: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4185 - accuracy: 0.8640 - top_3_accuracy: 0.9798 - top_5_accuracy: 0.9947 - val_loss: 0.5427 - val_accuracy: 0.8229 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 42/128\n",
      "3/3 [==============================] - 1s 176ms/step\n",
      "Epoch 42: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4363 - accuracy: 0.8526 - top_3_accuracy: 0.9762 - top_5_accuracy: 0.9912 - val_loss: 0.4694 - val_accuracy: 0.7917 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 1.0000 - 27s/epoch - 387ms/step\n",
      "Epoch 43/128\n",
      "3/3 [==============================] - 1s 176ms/step\n",
      "Epoch 43: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4274 - accuracy: 0.8521 - top_3_accuracy: 0.9833 - top_5_accuracy: 0.9930 - val_loss: 0.6419 - val_accuracy: 0.7917 - val_top_3_accuracy: 0.9375 - val_top_5_accuracy: 0.9688 - 27s/epoch - 387ms/step\n",
      "Epoch 44/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 44: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4035 - accuracy: 0.8688 - top_3_accuracy: 0.9815 - top_5_accuracy: 0.9960 - val_loss: 0.7019 - val_accuracy: 0.8125 - val_top_3_accuracy: 0.9375 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 45/128\n",
      "3/3 [==============================] - 1s 181ms/step\n",
      "Epoch 45: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.3770 - accuracy: 0.8759 - top_3_accuracy: 0.9846 - top_5_accuracy: 0.9969 - val_loss: 0.4037 - val_accuracy: 0.8542 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 1.0000 - 27s/epoch - 387ms/step\n",
      "Epoch 46/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 46: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.3845 - accuracy: 0.8592 - top_3_accuracy: 0.9820 - top_5_accuracy: 0.9965 - val_loss: 0.4673 - val_accuracy: 0.8021 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 47/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 47: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.3503 - accuracy: 0.8825 - top_3_accuracy: 0.9855 - top_5_accuracy: 0.9952 - val_loss: 0.7843 - val_accuracy: 0.7188 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 27s/epoch - 385ms/step\n",
      "Epoch 48/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 48: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.4217 - accuracy: 0.8574 - top_3_accuracy: 0.9762 - top_5_accuracy: 0.9938 - val_loss: 0.6672 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9375 - val_top_5_accuracy: 0.9688 - 27s/epoch - 385ms/step\n",
      "Epoch 49/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 49: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.3567 - accuracy: 0.8728 - top_3_accuracy: 0.9872 - top_5_accuracy: 0.9934 - val_loss: 0.5271 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 50/128\n",
      "3/3 [==============================] - 1s 173ms/step\n",
      "Epoch 50: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.3492 - accuracy: 0.8869 - top_3_accuracy: 0.9855 - top_5_accuracy: 0.9965 - val_loss: 0.5845 - val_accuracy: 0.8125 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 51/128\n",
      "3/3 [==============================] - 1s 173ms/step\n",
      "Epoch 51: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.3049 - accuracy: 0.8935 - top_3_accuracy: 0.9850 - top_5_accuracy: 0.9974 - val_loss: 0.4322 - val_accuracy: 0.8333 - val_top_3_accuracy: 0.9896 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 52/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 52: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2955 - accuracy: 0.8882 - top_3_accuracy: 0.9903 - top_5_accuracy: 0.9987 - val_loss: 0.5827 - val_accuracy: 0.8229 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 53/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 53: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.3066 - accuracy: 0.8974 - top_3_accuracy: 0.9833 - top_5_accuracy: 0.9974 - val_loss: 0.6324 - val_accuracy: 0.8229 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 54/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 54: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.3036 - accuracy: 0.8988 - top_3_accuracy: 0.9868 - top_5_accuracy: 0.9965 - val_loss: 0.5814 - val_accuracy: 0.8750 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 55/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 55: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2882 - accuracy: 0.9014 - top_3_accuracy: 0.9899 - top_5_accuracy: 0.9974 - val_loss: 0.5676 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9792 - 27s/epoch - 387ms/step\n",
      "Epoch 56/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 56: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.2865 - accuracy: 0.9032 - top_3_accuracy: 0.9934 - top_5_accuracy: 0.9978 - val_loss: 0.5411 - val_accuracy: 0.8333 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9792 - 28s/epoch - 388ms/step\n",
      "Epoch 57/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 57: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2682 - accuracy: 0.9058 - top_3_accuracy: 0.9908 - top_5_accuracy: 0.9982 - val_loss: 0.5739 - val_accuracy: 0.8542 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 58/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 58: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2864 - accuracy: 0.9018 - top_3_accuracy: 0.9890 - top_5_accuracy: 0.9965 - val_loss: 0.5363 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 59/128\n",
      "3/3 [==============================] - 1s 173ms/step\n",
      "Epoch 59: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2795 - accuracy: 0.8983 - top_3_accuracy: 0.9899 - top_5_accuracy: 0.9969 - val_loss: 0.5144 - val_accuracy: 0.8646 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 60/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 60: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2858 - accuracy: 0.9071 - top_3_accuracy: 0.9894 - top_5_accuracy: 0.9974 - val_loss: 0.6338 - val_accuracy: 0.8333 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 61/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 61: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.2577 - accuracy: 0.9177 - top_3_accuracy: 0.9930 - top_5_accuracy: 0.9987 - val_loss: 0.6969 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 28s/epoch - 389ms/step\n",
      "Epoch 62/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 62: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.2469 - accuracy: 0.9102 - top_3_accuracy: 0.9916 - top_5_accuracy: 0.9987 - val_loss: 0.9613 - val_accuracy: 0.8021 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9688 - 28s/epoch - 388ms/step\n",
      "Epoch 63/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 63: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.2679 - accuracy: 0.9080 - top_3_accuracy: 0.9916 - top_5_accuracy: 0.9996 - val_loss: 0.4258 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 28s/epoch - 387ms/step\n",
      "Epoch 64/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 64: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2543 - accuracy: 0.9142 - top_3_accuracy: 0.9903 - top_5_accuracy: 0.9987 - val_loss: 0.5795 - val_accuracy: 0.8542 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 65/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 65: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2172 - accuracy: 0.9221 - top_3_accuracy: 0.9930 - top_5_accuracy: 0.9991 - val_loss: 0.5400 - val_accuracy: 0.7917 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 66/128\n",
      "3/3 [==============================] - 1s 176ms/step\n",
      "Epoch 66: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.2223 - accuracy: 0.9243 - top_3_accuracy: 0.9930 - top_5_accuracy: 0.9982 - val_loss: 0.4475 - val_accuracy: 0.8125 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 28s/epoch - 388ms/step\n",
      "Epoch 67/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 67: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2298 - accuracy: 0.9247 - top_3_accuracy: 0.9960 - top_5_accuracy: 0.9987 - val_loss: 0.5500 - val_accuracy: 0.8750 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9688 - 27s/epoch - 387ms/step\n",
      "Epoch 68/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 68: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2310 - accuracy: 0.9159 - top_3_accuracy: 0.9912 - top_5_accuracy: 0.9996 - val_loss: 0.5793 - val_accuracy: 0.8333 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 69/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 69: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2308 - accuracy: 0.9243 - top_3_accuracy: 0.9934 - top_5_accuracy: 0.9987 - val_loss: 0.4968 - val_accuracy: 0.8333 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 70/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 70: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1837 - accuracy: 0.9384 - top_3_accuracy: 0.9956 - top_5_accuracy: 0.9991 - val_loss: 0.6908 - val_accuracy: 0.8229 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 71/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 71: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1522 - accuracy: 0.9419 - top_3_accuracy: 0.9982 - top_5_accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.8646 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 1.0000 - 27s/epoch - 386ms/step\n",
      "Epoch 72/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 72: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2057 - accuracy: 0.9340 - top_3_accuracy: 0.9943 - top_5_accuracy: 0.9987 - val_loss: 0.8847 - val_accuracy: 0.7812 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 73/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 73: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2128 - accuracy: 0.9252 - top_3_accuracy: 0.9930 - top_5_accuracy: 0.9996 - val_loss: 0.5100 - val_accuracy: 0.8542 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 74/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 74: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1863 - accuracy: 0.9366 - top_3_accuracy: 0.9952 - top_5_accuracy: 0.9982 - val_loss: 0.6718 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 75/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 75: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1881 - accuracy: 0.9344 - top_3_accuracy: 0.9956 - top_5_accuracy: 0.9996 - val_loss: 0.7604 - val_accuracy: 0.8021 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9792 - 27s/epoch - 387ms/step\n",
      "Epoch 76/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 76: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2030 - accuracy: 0.9309 - top_3_accuracy: 0.9925 - top_5_accuracy: 0.9991 - val_loss: 0.7024 - val_accuracy: 0.8125 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 77/128\n",
      "3/3 [==============================] - 1s 172ms/step\n",
      "Epoch 77: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2494 - accuracy: 0.9129 - top_3_accuracy: 0.9916 - top_5_accuracy: 0.9987 - val_loss: 0.7821 - val_accuracy: 0.7917 - val_top_3_accuracy: 0.9479 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 78/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 78: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2030 - accuracy: 0.9278 - top_3_accuracy: 0.9956 - top_5_accuracy: 0.9991 - val_loss: 0.6071 - val_accuracy: 0.8542 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 79/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 79: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1676 - accuracy: 0.9463 - top_3_accuracy: 0.9982 - top_5_accuracy: 0.9996 - val_loss: 0.7577 - val_accuracy: 0.8333 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 80/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 80: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.2343 - accuracy: 0.9190 - top_3_accuracy: 0.9943 - top_5_accuracy: 0.9987 - val_loss: 0.5968 - val_accuracy: 0.8229 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 81/128\n",
      "3/3 [==============================] - 1s 176ms/step\n",
      "Epoch 81: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1610 - accuracy: 0.9467 - top_3_accuracy: 0.9974 - top_5_accuracy: 0.9996 - val_loss: 0.5465 - val_accuracy: 0.8333 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 82/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 82: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1783 - accuracy: 0.9384 - top_3_accuracy: 0.9956 - top_5_accuracy: 0.9996 - val_loss: 0.6395 - val_accuracy: 0.8542 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 83/128\n",
      "3/3 [==============================] - 1s 173ms/step\n",
      "Epoch 83: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.1462 - accuracy: 0.9503 - top_3_accuracy: 0.9974 - top_5_accuracy: 0.9996 - val_loss: 0.6282 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 28s/epoch - 387ms/step\n",
      "Epoch 84/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 84: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1999 - accuracy: 0.9340 - top_3_accuracy: 0.9965 - top_5_accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9792 - 27s/epoch - 387ms/step\n",
      "Epoch 85/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 85: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1859 - accuracy: 0.9384 - top_3_accuracy: 0.9969 - top_5_accuracy: 0.9996 - val_loss: 0.6886 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 86/128\n",
      "3/3 [==============================] - 1s 174ms/step\n",
      "Epoch 86: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1458 - accuracy: 0.9494 - top_3_accuracy: 0.9974 - top_5_accuracy: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.8646 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 87/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 87: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1360 - accuracy: 0.9533 - top_3_accuracy: 0.9982 - top_5_accuracy: 0.9996 - val_loss: 0.4335 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 88/128\n",
      "3/3 [==============================] - 1s 173ms/step\n",
      "Epoch 88: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1793 - accuracy: 0.9379 - top_3_accuracy: 0.9965 - top_5_accuracy: 1.0000 - val_loss: 0.7696 - val_accuracy: 0.7917 - val_top_3_accuracy: 0.9375 - val_top_5_accuracy: 0.9688 - 27s/epoch - 387ms/step\n",
      "Epoch 89/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 89: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1498 - accuracy: 0.9463 - top_3_accuracy: 0.9969 - top_5_accuracy: 0.9991 - val_loss: 0.5653 - val_accuracy: 0.8646 - val_top_3_accuracy: 0.9792 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 90/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 90: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1528 - accuracy: 0.9472 - top_3_accuracy: 0.9969 - top_5_accuracy: 0.9991 - val_loss: 0.7796 - val_accuracy: 0.8542 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 91/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 91: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1496 - accuracy: 0.9494 - top_3_accuracy: 0.9982 - top_5_accuracy: 0.9996 - val_loss: 0.6657 - val_accuracy: 0.8333 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 92/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 92: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1802 - accuracy: 0.9371 - top_3_accuracy: 0.9960 - top_5_accuracy: 0.9987 - val_loss: 0.5653 - val_accuracy: 0.8542 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 93/128\n",
      "3/3 [==============================] - 1s 175ms/step\n",
      "Epoch 93: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.1615 - accuracy: 0.9450 - top_3_accuracy: 0.9947 - top_5_accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.8646 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 28s/epoch - 388ms/step\n",
      "Epoch 94/128\n",
      "3/3 [==============================] - 1s 173ms/step\n",
      "Epoch 94: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1965 - accuracy: 0.9327 - top_3_accuracy: 0.9960 - top_5_accuracy: 0.9991 - val_loss: 0.6772 - val_accuracy: 0.8021 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9792 - 27s/epoch - 386ms/step\n",
      "Epoch 95/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 95: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1348 - accuracy: 0.9555 - top_3_accuracy: 0.9974 - top_5_accuracy: 0.9996 - val_loss: 0.5909 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 27s/epoch - 386ms/step\n",
      "Epoch 96/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 96: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.1369 - accuracy: 0.9516 - top_3_accuracy: 0.9965 - top_5_accuracy: 0.9987 - val_loss: 0.7596 - val_accuracy: 0.8125 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 28s/epoch - 389ms/step\n",
      "Epoch 97/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 97: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.1966 - accuracy: 0.9388 - top_3_accuracy: 0.9960 - top_5_accuracy: 0.9996 - val_loss: 0.8318 - val_accuracy: 0.8229 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 28s/epoch - 388ms/step\n",
      "Epoch 98/128\n",
      "3/3 [==============================] - 1s 178ms/step\n",
      "Epoch 98: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1294 - accuracy: 0.9564 - top_3_accuracy: 0.9978 - top_5_accuracy: 0.9991 - val_loss: 0.6771 - val_accuracy: 0.8646 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 99/128\n",
      "3/3 [==============================] - 1s 177ms/step\n",
      "Epoch 99: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1280 - accuracy: 0.9626 - top_3_accuracy: 0.9987 - top_5_accuracy: 0.9996 - val_loss: 0.6083 - val_accuracy: 0.8542 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9896 - 27s/epoch - 387ms/step\n",
      "Epoch 100/128\n",
      "3/3 [==============================] - 1s 173ms/step\n",
      "Epoch 100: saved predictions and true labels\n",
      "71/71 - 27s - loss: 0.1320 - accuracy: 0.9533 - top_3_accuracy: 0.9978 - top_5_accuracy: 0.9987 - val_loss: 0.8094 - val_accuracy: 0.8438 - val_top_3_accuracy: 0.9583 - val_top_5_accuracy: 0.9792 - 27s/epoch - 387ms/step\n",
      "Epoch 101/128\n",
      "3/3 [==============================] - 1s 179ms/step\n",
      "Epoch 101: saved predictions and true labels\n",
      "71/71 - 28s - loss: 0.1239 - accuracy: 0.9547 - top_3_accuracy: 0.9965 - top_5_accuracy: 1.0000 - val_loss: 0.7828 - val_accuracy: 0.8333 - val_top_3_accuracy: 0.9688 - val_top_5_accuracy: 0.9792 - 28s/epoch - 388ms/step\n",
      "Epoch 102/128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#print(train_generator)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m save_predictions_callback \u001b[38;5;241m=\u001b[39m SavePredictionsCallback(X_test, Y_test)\n\u001b[0;32m---> 34\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_predictions_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     39\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(Y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234)\n",
    "print(target_subject)\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class SavePredictionsCallback(Callback):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.predictions_per_epoch = []\n",
    "        self.true_labels_per_epoch = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        self.predictions_per_epoch.append(y_pred)\n",
    "        self.true_labels_per_epoch.append(self.y_test)\n",
    "        print(f\"Epoch {epoch+1}: saved predictions and true labels\")\n",
    "        \n",
    "if config_params['training']['optimizer'] == 'adam':\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_late, epsilon=0.001)\n",
    "    \n",
    "elif config_params['training']['optimizer'] == 'sgd':\n",
    "    optimizer = optimizers.SGD(learning_rate=learning_late, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', top_3_accuracy, top_5_accuracy])\n",
    "\n",
    "train_callbacks = []\n",
    "\n",
    "lrScheduler = MyLRScheduler(**config_params['training']['l_rate_schedule'])\n",
    "train_callbacks.append(lrScheduler)\n",
    "#print(train_generator)\n",
    "\n",
    "save_predictions_callback = SavePredictionsCallback(X_test, Y_test)\n",
    "\n",
    "history = model.fit(train_generator, epochs=128, \n",
    "                              validation_data=(X_test,Y_test), callbacks=[save_predictions_callback], verbose=2)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_test = np.argmax(Y_test, axis=1)\n",
    "    \n",
    "#print(history.history)\n",
    "\n",
    "#acc_list.append(max(history.history['accuracy']))\n",
    "\n",
    "if config_params['model']['save']:\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(MODEL_SAVE_FILE.format(SUBJECT), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(MODEL_WEIGHTS_SAVE_FILE.format(SUBJECT))\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "# C_{i, j} is equal to the number of observations known to be in group i but predicted to be in group j.\n",
    "cnf_matrix_frame = metrics.confusion_matrix(y_test, y_pred)\n",
    "if np.array(mean_cm).shape != cnf_matrix_frame.shape:\n",
    "    mean_cm = cnf_matrix_frame\n",
    "else:\n",
    "    mean_cm += cnf_matrix_frame\n",
    "\n",
    "#dict_keys(['loss', 'accuracy', 'top_3_accuracy', 'top_5_accuracy', 'val_loss', 'val_accuracy', 'val_top_3_accuracy', 'val_top_5_accuracy'])\n",
    "\n",
    "mean_train.append(history.history['accuracy'][-1])\n",
    "mean_test.append(history.history['val_accuracy'][-1])\n",
    "mean_train_loss.append(history.history['loss'][-1])\n",
    "mean_test_loss.append(history.history['val_loss'][-1])\n",
    "mean_test_3.append(history.history['val_top_3_accuracy'][-1])\n",
    "mean_test_5.append(history.history['val_top_5_accuracy'][-1])\n",
    "\n",
    "if config_params['logging']['enable']:\n",
    "    with open(LOGGING_FILE, 'a') as f:\n",
    "        f.write('{},{},{},{},{},{},{},{},{}\\n'.format(SUBJECT, train_generator.__len__() * PARAMS_TRAIN_GENERATOR['batch_size'], valid_generator.__len__(),\n",
    "            mean_train_loss[-1], mean_train[-1], mean_test_loss[-1], mean_test[-1], mean_test_3[-1], mean_test_5[-1]))\n",
    "\n",
    "metrics_dict = {\n",
    "    'mean_cm': mean_cm,\n",
    "    'mean_test': mean_test,\n",
    "    'mean_test_3': mean_test_3,\n",
    "    'mean_test_5': mean_test_5,\n",
    "    'mean_train': mean_train,\n",
    "    'mean_train_loss': mean_train_loss,\n",
    "    'mean_test_loss': mean_test_loss\n",
    "}\n",
    "scipy.io.savemat(METRICS_SAVE_FILE.format(SUBJECT), metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da6889-6845-40d1-829c-6e0aa6cf08a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-----subject-------\")\n",
    "print(target_subject)\n",
    "print(\"----accuracy-----\")\n",
    "print(max(history.history['accuracy']))\n",
    "print(\"---val accuracy---\")\n",
    "print(max(history.history['val_accuracy']))\n",
    "\n",
    "predictions_per_epoch = save_predictions_callback.predictions_per_epoch\n",
    "true_labels_per_epoch = save_predictions_callback.true_labels_per_epoch\n",
    "\n",
    "for epoch, (y_pred, y_true) in enumerate(zip(predictions_per_epoch, true_labels_per_epoch)):\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    if (round(metrics.accuracy_score(y_test, y_pred),4) == round(max(history.history['val_accuracy']),4)):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        # print(\"Predictions:\", y_pred)\n",
    "        # print(\"True Labels:\", y_true)\n",
    "\n",
    "        report = classification_report(y_test, y_pred, digits=4)\n",
    "        print(report)\n",
    "\n",
    "target_subject += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33484b56-3a5c-4038-8327-49bb748eb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/sota/EMGcode/temp_result'\n",
    "file_name = f'DB4_report{target_subject-1}.txt'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(report)\n",
    "\n",
    "print(f\"Classification report saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac30a765-43af-47cc-b1e3-9792769f1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'repetitions': [1, 3, 4, 6], 'batch_size': 32, 'sample_weight': True, 'dim': [None, 12], 'classes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], 'shuffle': True, 'noise_snr_db': 25, 'scale_sigma': 0.0, 'window_size': 0, 'window_step': 0, 'rotation': 0, 'rotation_mask': None, 'time_warping': 0.2, 'mag_warping': 0.2, 'permutation': 0, 'data_type': 'rms', 'preprocess_function_1': [<function lpf at 0x7898aebc40d0>], 'preprocess_function_2': None, 'preprocess_function_1_extra': [{'fs': 100}], 'preprocess_function_2_extra': None, 'size_factor': 10, 'pad_len': None, 'pad_value': -10.0, 'min_max_norm': True, 'update_after_epoch': False, 'label_proc': None, 'label_proc_extra': None}\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "{'repetitions': [2, 5], 'batch_size': 32, 'sample_weight': False, 'dim': [None, 12], 'classes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], 'shuffle': False, 'noise_snr_db': 0, 'scale_sigma': 0.0, 'window_size': 0, 'window_step': 0, 'rotation': 0, 'rotation_mask': None, 'time_warping': 0.0, 'mag_warping': 0.0, 'permutation': 0, 'data_type': 'rms', 'preprocess_function_1': [<function lpf at 0x7898aebc40d0>], 'preprocess_function_2': None, 'preprocess_function_1_extra': [{'fs': 100}], 'preprocess_function_2_extra': None, 'size_factor': 10, 'pad_len': None, 'pad_value': -10.0, 'min_max_norm': True, 'update_after_epoch': False, 'label_proc': None, 'label_proc_extra': None}\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Classes: 52\n",
      "Class weights: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "Original dataset: 208\n",
      "Augmented dataset: 2288\n",
      "Number of sliding windows: 2288\n",
      "Batch size: 32\n",
      "Number of iterations: 71\n",
      "Window size: 0\n",
      "Window step: 0\n",
      "Pad length: 10886\n",
      "Output shape: (10886, 12)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Classes: 52\n",
      "Class weights: []\n",
      "Original dataset: 104\n",
      "Augmented dataset: 104\n",
      "Number of sliding windows: 104\n",
      "Batch size: 32\n",
      "Number of iterations: 3\n",
      "Window size: 0\n",
      "Window step: 0\n",
      "Pad length: 10885\n",
      "Output shape: (10885, 12)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(PARAMS_TRAIN_GENERATOR)\n",
    "print('\\n---------------------------------------------------------------------------\\n')\n",
    "print(PARAMS_VALID_GENERATOR)\n",
    "print('\\n---------------------------------------------------------------------------\\n')\n",
    "print(train_generator)\n",
    "print('---------------------------------------------------------------------------\\n')\n",
    "print(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a858e88d-5fbe-4451-af17-c6d0b4a20451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'repetitions': [1, 3, 4, 6], 'batch_size': 32, 'sample_weight': True, 'dim': [None, 12], 'classes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], 'shuffle': True, 'noise_snr_db': 25, 'scale_sigma': 0.0, 'window_size': 0, 'window_step': 0, 'rotation': 0, 'rotation_mask': None, 'time_warping': 0.2, 'mag_warping': 0.2, 'permutation': 0, 'data_type': 'rms', 'preprocess_function_1': [<function lpf at 0x728bb9fbc3a0>], 'preprocess_function_2': None, 'preprocess_function_1_extra': [{'fs': 100}], 'preprocess_function_2_extra': None, 'size_factor': 10, 'pad_len': None, 'pad_value': -10.0, 'min_max_norm': True, 'update_after_epoch': False, 'label_proc': None, 'label_proc_extra': None}\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "{'repetitions': [2, 5], 'batch_size': 32, 'sample_weight': False, 'dim': [None, 12], 'classes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], 'shuffle': False, 'noise_snr_db': 0, 'scale_sigma': 0.0, 'window_size': 0, 'window_step': 0, 'rotation': 0, 'rotation_mask': None, 'time_warping': 0.0, 'mag_warping': 0.0, 'permutation': 0, 'data_type': 'rms', 'preprocess_function_1': [<function lpf at 0x728bb9fbc3a0>], 'preprocess_function_2': None, 'preprocess_function_1_extra': [{'fs': 100}], 'preprocess_function_2_extra': None, 'size_factor': 10, 'pad_len': None, 'pad_value': -10.0, 'min_max_norm': True, 'update_after_epoch': False, 'label_proc': None, 'label_proc_extra': None}\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Classes: 52\n",
      "Class weights: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "Original dataset: 208\n",
      "Augmented dataset: 2288\n",
      "Number of sliding windows: 2288\n",
      "Batch size: 32\n",
      "Number of iterations: 71\n",
      "Window size: 0\n",
      "Window step: 0\n",
      "Pad length: 13427\n",
      "Output shape: (13427, 12)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Classes: 52\n",
      "Class weights: []\n",
      "Original dataset: 104\n",
      "Augmented dataset: 104\n",
      "Number of sliding windows: 104\n",
      "Batch size: 32\n",
      "Number of iterations: 3\n",
      "Window size: 0\n",
      "Window step: 0\n",
      "Pad length: 12913\n",
      "Output shape: (12913, 12)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(PARAMS_TRAIN_GENERATOR)\n",
    "print('---------------------------------------------------------------------------\\n')\n",
    "print(PARAMS_VALID_GENERATOR)\n",
    "print('---------------------------------------------------------------------------\\n')\n",
    "print(train_generator)\n",
    "print('---------------------------------------------------------------------------\\n')\n",
    "print(valid_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

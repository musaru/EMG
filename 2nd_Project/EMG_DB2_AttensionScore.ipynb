{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ea7e41-a9cc-4623-a981-71ef23e5141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:03:05.103318: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-15 08:03:05.818461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Keras: 2.12.0\n",
      "Tensorflow: 2.12.0\n",
      "Logging file: ./Result/L_TCCNet_att_20250415080309.log\n",
      "Tensorboard file: ./Result/tblogs/L_TCCNet_att_20250415080309\n",
      "Model JSON file: ./Result/models/O1_TCCNet_att_20250415080309_{}.json\n",
      "Model H5 file: ./Result/models/O2_TCCNet_att_20250415080309_{}.h5\n",
      "Metrics file: ./Result/metrics/O3_TCCNet_att_20250415080309_{}.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:03:09.087236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 08:03:09.100674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 08:03:09.100740: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 08:03:09.104840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 08:03:09.104898: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 08:03:09.104939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 08:03:09.235119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 08:03:09.235230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 08:03:09.235241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-15 08:03:09.235303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 08:03:09.235336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21770 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:33:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import sys\n",
    "# ----------- change the paths according to your environment -----------\n",
    "sys.path.append('.')\n",
    "import mypreprocessing\n",
    "from generator import DataGenerator\n",
    "from models import getNetwork\n",
    "from custom_layers import MeanOverTime\n",
    "import sys, os\n",
    "import json\n",
    "import scipy\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import optimizers, initializers, regularizers, constraints\n",
    "from utils import *\n",
    "from sklearn import metrics\n",
    "import matplotlib as plt\n",
    "from keras.layers import *\n",
    "from tcn import TCN\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyp\n",
    "from keras.layers import Layer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class ChannelAttention(Layer):\n",
    "    def __init__(self, ratio = 8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=self.channels // self.ratio,\n",
    "                                           activation='relu',\n",
    "                                           kernel_initializer='he_normal',\n",
    "                                           use_bias=True)\n",
    "        self.dense_output = tf.keras.layers.Dense(units=self.channels,\n",
    "                                                  kernel_initializer='he_normal',\n",
    "                                                  use_bias=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs = tf.expand_dims(inputs, axis=2)\n",
    "        gap = tf.reduce_mean(inputs, axis=[0, 1], keepdims=True)\n",
    "\n",
    "        attention = self.dense(gap)\n",
    "        attention = self.dense_output(attention)\n",
    "        attention = tf.keras.activations.sigmoid(attention)\n",
    "\n",
    "        output = tf.multiply(inputs, attention)\n",
    "\n",
    "        return output\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "print('OK')\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "folder_process_data = './DB2'\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "print('Keras:', keras.__version__)\n",
    "print('Tensorflow:', tf.__version__)\n",
    "\n",
    "# 1. Logging\n",
    "'''\n",
    "if len(sys.argv) == 4:\n",
    "    CONFIG_FILE = str(sys.argv[1])\n",
    "    SUBJECT = int(sys.argv[2])\n",
    "    TIMESTAMP = int(sys.argv[3])\n",
    "else:\n",
    "    print('Expected different number of arguments. {} were given'.format(len(sys.argv) - 1))\n",
    "    sys.exit()\n",
    "    '''\n",
    "# ----------- change the paths according to your environment -----------\n",
    "CONFIG_FILE='./config_DB2/TCCNet_aot_2500.json'\n",
    "import datetime\n",
    "from datetime import date\n",
    "SUBJECT=1\n",
    "GESTURES=50\n",
    "currentDateAndTime = datetime.datetime.now()\n",
    "\n",
    "current_date = datetime.datetime.now()\n",
    "TIMESTAMP = current_date .strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# ----------- change the paths according to your environment -----------\n",
    "with open(CONFIG_FILE) as json_file:\n",
    "    config_params = json.load(json_file)\n",
    "outdir='./Result'\n",
    "LOGGING_FILE_PREFIX = config_params['logging']['log_file'] + '_' + str(TIMESTAMP)\n",
    "if config_params['logging']['enable']:\n",
    "    LOGGING_FILE = './Result/L_' + LOGGING_FILE_PREFIX + '.log'# 'Musa_NinaPro_Project/ProcessedData/DB1/Result/L_' + LOGGING_FILE_PREFIX + '.log'\n",
    "    LOGGING_TENSORBOARD_FILE = './Result/tblogs/L_' + LOGGING_FILE_PREFIX #'Musa_NinaPro_Project/ProcessedData/DB1/Result/tblogs/L_' + LOGGING_FILE_PREFIX\n",
    "\n",
    "if config_params['model']['save']:\n",
    "    MODEL_SAVE_FILE = './Result/models/O1_' + LOGGING_FILE_PREFIX + '_{}.json'\n",
    "    MODEL_WEIGHTS_SAVE_FILE = './Result/models/O2_' + LOGGING_FILE_PREFIX + '_{}.h5'\n",
    "\n",
    "METRICS_SAVE_FILE = './Result/metrics/O3_' + LOGGING_FILE_PREFIX + '_{}.mat'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(METRICS_SAVE_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(METRICS_SAVE_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "if not os.path.exists(os.path.dirname(MODEL_SAVE_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(MODEL_SAVE_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "if not os.path.exists(os.path.dirname(LOGGING_TENSORBOARD_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(LOGGING_TENSORBOARD_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "\n",
    "print('Logging file: {}'.format(LOGGING_FILE))\n",
    "print('Tensorboard file: {}'.format(LOGGING_TENSORBOARD_FILE))\n",
    "print('Model JSON file: {}'.format(MODEL_SAVE_FILE))\n",
    "print('Model H5 file: {}'.format(MODEL_WEIGHTS_SAVE_FILE))\n",
    "print('Metrics file: {}'.format(METRICS_SAVE_FILE))\n",
    "\n",
    "# 2. Config params generator\n",
    "PARAMS_TRAIN_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('train_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_TRAIN_GENERATOR[key] = params_gen[key]\n",
    "\n",
    "PARAMS_VALID_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('valid_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_VALID_GENERATOR[key] = params_gen[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09c4de4-0fa9-44d4-97f6-2f05b6716d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_subject = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fadb5cf0-9eac-4365-b797-247a2fb3dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the data from subject 1 have loaded.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import mypreprocessing\n",
    "from DB2_Mydataset import *\n",
    "from models import getNetwork\n",
    "import keras\n",
    "from keras import optimizers, initializers, regularizers, constraints\n",
    "from utils import *\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Environment settings\n",
    "folder_process_data = './DB2'\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(1234)\n",
    "random.seed(12345)\n",
    "\n",
    "# GPU configuration\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# Logging settings\n",
    "SUBJECT = 1\n",
    "GESTURES = 50\n",
    "\n",
    "# Create save directories if they don't exist\n",
    "def create_directory_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "create_directory_if_not_exists(os.path.dirname(METRICS_SAVE_FILE))\n",
    "create_directory_if_not_exists(os.path.dirname(MODEL_SAVE_FILE))\n",
    "create_directory_if_not_exists(os.path.dirname(LOGGING_TENSORBOARD_FILE))\n",
    "\n",
    "# Initialize parameters\n",
    "PARAMS_TRAIN_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('train_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_TRAIN_GENERATOR[key] = params_gen[key]\n",
    "\n",
    "PARAMS_VALID_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('valid_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_VALID_GENERATOR[key] = params_gen[key]\n",
    "\n",
    "# Prepare data\n",
    "INPUT_DIRECTORY = folder_process_data\n",
    "PARAMS_TRAIN_GENERATOR.update({\n",
    "    'preprocess_function_1': [mypreprocessing.lpf],\n",
    "    'preprocess_function_1_extra': [{'fs': 100}],\n",
    "    'data_type': 'rms',\n",
    "    'classes': [i for i in range(50)],\n",
    "    'dim': [1, 12],\n",
    "    'repetitions': [1, 3, 4, 6],\n",
    "    'min_max_norm': True,\n",
    "    'batch_size': 64\n",
    "})\n",
    "\n",
    "PARAMS_VALID_GENERATOR.update({\n",
    "    'preprocess_function_1': [mypreprocessing.lpf],\n",
    "    'preprocess_function_1_extra': [{'fs': 100}],\n",
    "    'data_type': 'rms',\n",
    "    'classes': [i for i in range(50)],\n",
    "    'dim': [1, 12],\n",
    "    'repetitions': [2, 5],\n",
    "    'min_max_norm': True,\n",
    "    'batch_size': 64\n",
    "})\n",
    "\n",
    "# Remove 'input_directory' key\n",
    "PARAMS_TRAIN_GENERATOR.pop('input_directory', None)\n",
    "PARAMS_VALID_GENERATOR.pop('input_directory', None)\n",
    "\n",
    "# Load data\n",
    "input_dir = f'{INPUT_DIRECTORY}/subject-{SUBJECT:02d}'\n",
    "train_generator = DataGenerator(input_directory=input_dir, **PARAMS_TRAIN_GENERATOR)\n",
    "valid_generator = DataGenerator(input_directory=input_dir, **PARAMS_VALID_GENERATOR)\n",
    "\n",
    "X_train, Y_train, train_reps, L_ = train_generator.get_data()\n",
    "y_train = np.where(Y_train == 1)[1]\n",
    "\n",
    "X_test, Y_test, test_reps = valid_generator.get_data()\n",
    "y_test = np.where(Y_test == 1)[1]\n",
    "\n",
    "# Reshape data\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "train_dataset = Hand_Dataset(X_train, y_train)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "test_dataset = Hand_Dataset(X_test, y_test)\n",
    "\n",
    "class_num = train_generator.n_classes\n",
    "timelen = X_train.shape[1]\n",
    "\n",
    "print(f'Now the data from subject {format(SUBJECT)} have loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df06ae23-e72e-4257-a290-fb19ac56b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:03:50.186012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:03:50.187588: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:03:50.188604: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 08:03:50.279625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 08:03:50.311391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:03:50.312643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:03:50.313881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 08:03:51.625238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-04-15 08:03:52.059573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:03:52.061069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:03:52.062366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 08:03:52.155292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 08:03:52.472219: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:03:52.474180: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:03:52.475397: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 08:03:53.354447: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 08:03:54.521975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:03:54.524094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:03:54.525095: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 08:03:54.625389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 08:03:54.661292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:03:54.662441: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:03:54.663517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 08:03:55.592909: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 08:03:57.596703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8906\n",
      "2025-04-15 08:03:57.723751: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-15 08:03:57.724880: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-15 08:03:57.724923: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2025-04-15 08:03:57.725946: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-15 08:03:57.726217: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:317] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2025-04-15 08:03:58.564742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-04-15 08:05:53.137482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:05:53.140608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:05:53.145694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 08:05:53.278621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 08:05:53.325022: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:05:53.326300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:05:53.328025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 08:05:56.535359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:05:56.536961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:05:56.538168: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 08:05:56.662479: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 08:05:56.704955: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 08:05:56.706412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 08:05:56.707760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 427ms/step\n",
      "Epoch 1: saved predictions and attention scores\n",
      "40/40 - 127s - loss: 6.0693 - dense_2_loss: 6.0693 - dense_2_accuracy: 0.0230 - dense_2_top_3_accuracy: 0.0785 - dense_2_top_5_accuracy: 0.1285 - val_loss: 3.8811 - val_dense_2_loss: 3.8811 - val_dense_2_accuracy: 0.0000e+00 - val_dense_2_top_3_accuracy: 0.1406 - val_dense_2_top_5_accuracy: 0.2500 - 127s/epoch - 3s/step\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 1s 463ms/step\n",
      "Epoch 2: saved predictions and attention scores\n",
      "40/40 - 69s - loss: 3.8971 - dense_2_loss: 3.8971 - dense_2_accuracy: 0.0473 - dense_2_top_3_accuracy: 0.1117 - dense_2_top_5_accuracy: 0.1594 - val_loss: 3.8333 - val_dense_2_loss: 3.8333 - val_dense_2_accuracy: 0.0781 - val_dense_2_top_3_accuracy: 0.1562 - val_dense_2_top_5_accuracy: 0.2500 - 69s/epoch - 2s/step\n",
      "Saved attention scores and labels to 'final_attention_scores.mat'\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback\n",
    "from tcn import TCN\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import scipy.io\n",
    "\n",
    "# Channel Attention Layer\n",
    "class ChannelAttention(Layer):\n",
    "    def __init__(self, ratio=8, **kwargs):\n",
    "        super(ChannelAttention, self).__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "        self.dense = Dense(units=self.channels // self.ratio,\n",
    "                           activation='relu',\n",
    "                           kernel_initializer='he_normal',\n",
    "                           use_bias=True)\n",
    "        self.dense_output = Dense(units=self.channels,\n",
    "                                  kernel_initializer='he_normal',\n",
    "                                  use_bias=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gap = tf.reduce_mean(inputs, axis=2, keepdims=True)\n",
    "        attention = self.dense(gap)\n",
    "        attention = self.dense_output(attention)\n",
    "        attention = tf.keras.activations.sigmoid(attention)\n",
    "        return inputs * attention, attention  # Two outputs!\n",
    "\n",
    "# SE Block\n",
    "def se_block(in_block, ch, ratio=16):\n",
    "    z = GlobalAveragePooling1D()(in_block)\n",
    "    x = Dense(ch // ratio, activation='relu')(z)\n",
    "    x = Dense(ch, activation='sigmoid')(x)\n",
    "    return multiply([in_block, x])\n",
    "\n",
    "# Build the model\n",
    "columns = 12\n",
    "gestures = 50\n",
    "input = Input(shape=(None, columns))  # (time, 12)\n",
    "\n",
    "# Build each branch\n",
    "branch1 = TCN(nb_filters=12, nb_stacks=1, kernel_size=3, padding='same', return_sequences=True)(input)\n",
    "branch1 = Bidirectional(LSTM(64, return_sequences=True))(branch1)\n",
    "\n",
    "branch2 = Conv1D(16, 3, padding='same')(input)\n",
    "branch2 = SeparableConv1D(filters=16, kernel_size=3, padding='same', activation='relu')(branch2)\n",
    "branch2 = se_block(branch2, ch=16)\n",
    "\n",
    "branch3 = Bidirectional(TCN(nb_filters=32, nb_stacks=1, kernel_size=3, padding='same', return_sequences=True))(input)\n",
    "\n",
    "# Merge all branches\n",
    "x = concatenate([branch1, branch2, branch3])  # shape: (batch, time, channels)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(12, kernel_size=1, padding='same')(x)  # shape: (batch, time, 12)\n",
    "x, attention_scores = ChannelAttention()(x)  # Apply ChannelAttention\n",
    "\n",
    "# Dimensionality reduction with GlobalAveragePooling\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "output = Dense(gestures, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input, outputs=[output, attention_scores])  # Note: two outputs\n",
    "\n",
    "# Save predictions and attention scores after each epoch\n",
    "class SavePredictionsCallback(Callback):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.predictions_per_epoch = []\n",
    "        self.true_labels_per_epoch = []\n",
    "        self.attention_scores_per_epoch = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred, attention_scores = self.model.predict(self.X_test)\n",
    "        self.predictions_per_epoch.append(y_pred)\n",
    "        self.true_labels_per_epoch.append(self.y_test)\n",
    "        self.attention_scores_per_epoch.append(attention_scores)\n",
    "        print(f\"Epoch {epoch+1}: saved predictions and attention scores\")\n",
    "\n",
    "train_callbacks = []\n",
    "\n",
    "# Add to callbacks\n",
    "save_predictions_callback = SavePredictionsCallback(X_test, Y_test)\n",
    "train_callbacks.append(save_predictions_callback)\n",
    "\n",
    "# Optimizer setup\n",
    "learning_rate = 0.001\n",
    "config_params = {'training': {'optimizer': 'adam'}}  # Example config\n",
    "if config_params['training']['optimizer'] == 'adam':\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate, epsilon=0.001)\n",
    "elif config_params['training']['optimizer'] == 'sgd':\n",
    "    optimizer = optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "# Define metrics (example: top-3 and top-5 accuracy)\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_5_accuracy(y_true, y_pred):\n",
    "    return tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=['categorical_crossentropy', None],  # Use categorical crossentropy for classification\n",
    "    metrics=[['accuracy', top_3_accuracy, top_5_accuracy], []]  # Define the metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=2,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    callbacks=train_callbacks, verbose=2)\n",
    "\n",
    "# Save the results from the final epoch\n",
    "final_attention = save_predictions_callback.attention_scores_per_epoch[-1]\n",
    "final_labels = save_predictions_callback.true_labels_per_epoch[-1]\n",
    "\n",
    "# attention_scores shape: (samples, time_steps, channels)\n",
    "# Save with time_steps as a dimension\n",
    "scipy.io.savemat('final_attention_scores.mat', {\n",
    "    'attention_scores': final_attention,  # (samples, time_steps, channels)\n",
    "    'labels': final_labels                # (samples, num_classes)\n",
    "})\n",
    "print(\"Saved attention scores and labels to 'final_attention_scores.mat'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b92d32a-c979-46a8-b759-8b8b6b5a0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 has no samples.\n",
      "✅ Done: Saved 1 file per class in horizontal format (TimeStep + 12 channels) under 'class_csv' folder.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load .mat file\n",
    "data = scipy.io.loadmat('final_attention_scores.mat')\n",
    "attention_scores = data['attention_scores']  # shape: (samples, time_steps, channels)\n",
    "labels_onehot = data['labels']               # shape: (samples, num_classes)\n",
    "labels = np.argmax(labels_onehot, axis=1)    # Convert to class indices\n",
    "\n",
    "num_classes = np.max(labels) + 1\n",
    "time_steps = attention_scores.shape[1]\n",
    "num_channels = attention_scores.shape[2]\n",
    "\n",
    "summary_table = []\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"class_csv\", exist_ok=True)\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    idx = np.where(labels == cls)[0]\n",
    "    if len(idx) == 0:\n",
    "        print(f\"Class {cls+1} has no samples.\")\n",
    "        continue\n",
    "\n",
    "    class_attention = attention_scores[idx]  # shape: (samples_in_class, time_steps, channels)\n",
    "    mean_attention = np.mean(class_attention, axis=0)  # shape: (time_steps, channels)\n",
    "\n",
    "    # ---- Plot ----\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for ch in range(min(num_channels, 12)):\n",
    "        plt.plot(mean_attention[:, ch], label=f'Ch{ch+1}')\n",
    "    plt.title(f'Average Attention Scores (Class {cls+1})')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Attention Score')\n",
    "    plt.legend(loc='upper right', ncol=2)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'class_{cls+1:02d}_attention_12ch.png')\n",
    "    plt.close()\n",
    "\n",
    "    # ---- Save CSV (horizontal format) ----\n",
    "    df_class = pd.DataFrame(mean_attention[:, :12], columns=[f'Ch{i+1}' for i in range(12)])\n",
    "    df_class.insert(0, 'TimeStep', np.arange(time_steps))  # Insert TimeStep column at the beginning\n",
    "    df_class.to_csv(f'class_csv/class{cls+1:02d}_12ch.csv', index=False)\n",
    "\n",
    "    # ---- Compute overall mean score ----\n",
    "    overall_mean = np.mean(mean_attention[:, :12])\n",
    "    summary_table.append([cls+1, overall_mean])\n",
    "\n",
    "# ---- Save summary ----\n",
    "df_summary = pd.DataFrame(summary_table, columns=['Class', 'Mean_Attention'])\n",
    "df_summary.to_csv('attention_summary_12ch.csv', index=False)\n",
    "\n",
    "print(\"✅ Done: Saved 1 file per class in horizontal format (TimeStep + 12 channels) under 'class_csv' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e8a4291-4f51-4051-9a87-dd65bc559c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 has no samples.\n",
      "✅ Done: Averaged 12 channels → cut first 400 time steps → plotted & saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load .mat file\n",
    "data = scipy.io.loadmat('final_attention_scores.mat')\n",
    "attention_scores = data['attention_scores']  # shape: (samples, time_steps, channels)\n",
    "labels_onehot = data['labels']               # shape: (samples, num_classes)\n",
    "labels = np.argmax(labels_onehot, axis=1)    # Convert one-hot to class indices\n",
    "\n",
    "# ---- ✅ Average across all channels to get a single-channel attention score ----\n",
    "attention_scores = np.mean(attention_scores, axis=2, keepdims=True)  # shape: (samples, time_steps, 1)\n",
    "\n",
    "# ---- ✅ Cut off the first 400 time steps ----\n",
    "attention_scores = attention_scores[:, 400:, :]  # shape: (samples, time_steps - 400, 1)\n",
    "\n",
    "num_classes = np.max(labels) + 1\n",
    "time_steps = attention_scores.shape[1]\n",
    "\n",
    "summary_table = []\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    idx = np.where(labels == cls)[0]\n",
    "    if len(idx) == 0:\n",
    "        print(f\"Class {cls+1} has no samples.\")\n",
    "        continue\n",
    "\n",
    "    class_attention = attention_scores[idx]  # shape: (samples_in_class, time_steps, 1)\n",
    "    mean_attention = np.mean(class_attention, axis=0)  # shape: (time_steps, 1)\n",
    "\n",
    "    # ---- Plot ----\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(mean_attention[:, 0], label='AvgCh')  # Only 1 channel\n",
    "    plt.title(f'Average Attention Scores (Class {cls+1})')\n",
    "    plt.xlabel('Time step (after cutting first 400)')\n",
    "    plt.ylabel('Attention Score')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'class_{cls+1:02d}_ave_attention.png')\n",
    "    plt.close()\n",
    "\n",
    "    # ---- Save overall mean attention score (mean across time steps) ----\n",
    "    overall_mean = np.mean(mean_attention)\n",
    "    summary_table.append([cls+1, overall_mean])\n",
    "\n",
    "# ---- Save summary as CSV ----\n",
    "df = pd.DataFrame(summary_table, columns=['Class', 'Mean_Attention'])\n",
    "df.to_csv('attention_summary.csv', index=False)\n",
    "\n",
    "print(\"✅ Done: Averaged 12 channels → cut first 400 time steps → plotted & saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f377dc75-77c2-487f-9499-bea4590d6a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

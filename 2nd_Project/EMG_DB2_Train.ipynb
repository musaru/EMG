{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b005b2a7-1926-47eb-a255-2022e8ec027a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 07:52:23.101828: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-15 07:52:24.002259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Keras: 2.12.0\n",
      "Tensorflow: 2.12.0\n",
      "Logging file: ./Result/L_TCCNet_att_20250415075228.log\n",
      "Tensorboard file: ./Result/tblogs/L_TCCNet_att_20250415075228\n",
      "Model JSON file: ./Result/models/O1_TCCNet_att_20250415075228_{}.json\n",
      "Model H5 file: ./Result/models/O2_TCCNet_att_20250415075228_{}.h5\n",
      "Metrics file: ./Result/metrics/O3_TCCNet_att_20250415075228_{}.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 07:52:28.337915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 07:52:28.379552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 07:52:28.379626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 07:52:28.388527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 07:52:28.388599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 07:52:28.388650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 07:52:28.488042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 07:52:28.488152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 07:52:28.488160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-15 07:52:28.488217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:33:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-15 07:52:28.488246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21770 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:33:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import sys\n",
    "# ----------- change the paths according to your environment -----------\n",
    "sys.path.append('.')\n",
    "import mypreprocessing\n",
    "from generator import DataGenerator\n",
    "from models import getNetwork\n",
    "from custom_layers import MeanOverTime\n",
    "import sys, os\n",
    "import json\n",
    "import scipy\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import optimizers, initializers, regularizers, constraints\n",
    "from utils import *\n",
    "from sklearn import metrics\n",
    "import matplotlib as plt\n",
    "from keras.layers import *\n",
    "from tcn import TCN\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyp\n",
    "from keras.layers import Layer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class ChannelAttention(Layer):\n",
    "    def __init__(self, ratio = 8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=self.channels // self.ratio,\n",
    "                                           activation='relu',\n",
    "                                           kernel_initializer='he_normal',\n",
    "                                           use_bias=True)\n",
    "        self.dense_output = tf.keras.layers.Dense(units=self.channels,\n",
    "                                                  kernel_initializer='he_normal',\n",
    "                                                  use_bias=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs = tf.expand_dims(inputs, axis=2)\n",
    "        gap = tf.reduce_mean(inputs, axis=[0, 1], keepdims=True)\n",
    "\n",
    "        attention = self.dense(gap)\n",
    "        attention = self.dense_output(attention)\n",
    "        attention = tf.keras.activations.sigmoid(attention)\n",
    "\n",
    "        output = tf.multiply(inputs, attention)\n",
    "\n",
    "        return output\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "print('OK')\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "folder_process_data = './DB2'\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "print('Keras:', keras.__version__)\n",
    "print('Tensorflow:', tf.__version__)\n",
    "\n",
    "# 1. Logging\n",
    "'''\n",
    "if len(sys.argv) == 4:\n",
    "    CONFIG_FILE = str(sys.argv[1])\n",
    "    SUBJECT = int(sys.argv[2])\n",
    "    TIMESTAMP = int(sys.argv[3])\n",
    "else:\n",
    "    print('Expected different number of arguments. {} were given'.format(len(sys.argv) - 1))\n",
    "    sys.exit()\n",
    "    '''\n",
    "# ----------- change the paths according to your environment -----------\n",
    "CONFIG_FILE='./config_DB2/TCCNet_aot_2500.json'\n",
    "import datetime\n",
    "from datetime import date\n",
    "SUBJECT=1\n",
    "GESTURES=50\n",
    "currentDateAndTime = datetime.datetime.now()\n",
    "\n",
    "current_date = datetime.datetime.now()\n",
    "TIMESTAMP = current_date .strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# ----------- change the paths according to your environment -----------\n",
    "with open(CONFIG_FILE) as json_file:\n",
    "    config_params = json.load(json_file)\n",
    "outdir='./Result'\n",
    "LOGGING_FILE_PREFIX = config_params['logging']['log_file'] + '_' + str(TIMESTAMP)\n",
    "if config_params['logging']['enable']:\n",
    "    LOGGING_FILE = './Result/L_' + LOGGING_FILE_PREFIX + '.log'# 'Musa_NinaPro_Project/ProcessedData/DB1/Result/L_' + LOGGING_FILE_PREFIX + '.log'\n",
    "    LOGGING_TENSORBOARD_FILE = './Result/tblogs/L_' + LOGGING_FILE_PREFIX #'Musa_NinaPro_Project/ProcessedData/DB1/Result/tblogs/L_' + LOGGING_FILE_PREFIX\n",
    "\n",
    "if config_params['model']['save']:\n",
    "    MODEL_SAVE_FILE = './Result/models/O1_' + LOGGING_FILE_PREFIX + '_{}.json'\n",
    "    MODEL_WEIGHTS_SAVE_FILE = './Result/models/O2_' + LOGGING_FILE_PREFIX + '_{}.h5'\n",
    "\n",
    "METRICS_SAVE_FILE = './Result/metrics/O3_' + LOGGING_FILE_PREFIX + '_{}.mat'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(METRICS_SAVE_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(METRICS_SAVE_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "if not os.path.exists(os.path.dirname(MODEL_SAVE_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(MODEL_SAVE_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "if not os.path.exists(os.path.dirname(LOGGING_TENSORBOARD_FILE)):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(LOGGING_TENSORBOARD_FILE))\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "\n",
    "print('Logging file: {}'.format(LOGGING_FILE))\n",
    "print('Tensorboard file: {}'.format(LOGGING_TENSORBOARD_FILE))\n",
    "print('Model JSON file: {}'.format(MODEL_SAVE_FILE))\n",
    "print('Model H5 file: {}'.format(MODEL_WEIGHTS_SAVE_FILE))\n",
    "print('Metrics file: {}'.format(METRICS_SAVE_FILE))\n",
    "\n",
    "# 2. Config params generator\n",
    "PARAMS_TRAIN_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('train_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_TRAIN_GENERATOR[key] = params_gen[key]\n",
    "\n",
    "PARAMS_VALID_GENERATOR = DEFAULT_GENERATOR_PARAMS.copy()\n",
    "params_gen = config_params['dataset'].get('valid_generator', {}).copy()\n",
    "for key in params_gen.keys():\n",
    "    PARAMS_VALID_GENERATOR[key] = params_gen[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43550042-77ae-4eec-847f-7e237b566eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_subject = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee81625-b291-4679-9049-5972351f1bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 1\n"
     ]
    }
   ],
   "source": [
    "# 3. Initialization\n",
    "INPUT_DIRECTORY = 'DB2'\n",
    "quarter_batch = True\n",
    "\n",
    "#INPUT_DIRECTORY = folder_process_data        #link of processed dataset\n",
    "PARAMS_TRAIN_GENERATOR['preprocess_function_1'] = [mypreprocessing.lpf]\n",
    "PARAMS_TRAIN_GENERATOR['preprocess_function_1_extra'] = [{'fs': 100}]\n",
    "PARAMS_TRAIN_GENERATOR['data_type'] = 'rms'\n",
    "PARAMS_TRAIN_GENERATOR['classes'] = [i for i in range(50)]#+[0]\n",
    "PARAMS_TRAIN_GENERATOR['repetitions'] = [1, 3, 4, 6]\n",
    "# PARAMS_TRAIN_GENERATOR['dim'] = [1,10]\n",
    "# PARAMS_TRAIN_GENERATOR['window_size'] = 200\n",
    "# PARAMS_TRAIN_GENERATOR['window_step'] = 50\n",
    "\n",
    "PARAMS_VALID_GENERATOR['preprocess_function_1'] = [mypreprocessing.lpf]\n",
    "PARAMS_VALID_GENERATOR['preprocess_function_1_extra'] = [{'fs': 100}]\n",
    "PARAMS_VALID_GENERATOR['data_type'] = 'rms'\n",
    "PARAMS_VALID_GENERATOR['classes'] = [i for i in range(50)]#+[0]\n",
    "PARAMS_VALID_GENERATOR['repetitions'] = [2, 5]\n",
    "# PARAMS_VALID_GENERATOR['dim'] = [1,10]\n",
    "# PARAMS_VALID_GENERATOR['window_size'] = 200\n",
    "# PARAMS_VALID_GENERATOR['window_step'] = 50\n",
    "\n",
    "if quarter_batch == True:\n",
    "    PARAMS_TRAIN_GENERATOR['batch_size'] = int(64)\n",
    "    PARAMS_VALID_GENERATOR['batch_size'] = int(64)\n",
    "    # PARAMS_TRAIN_GENERATOR['batch_size'] = int(128/16)\n",
    "    # PARAMS_VALID_GENERATOR['batch_size'] = int(128/16)\n",
    "    learning_late = config_params['training']['l_rate']/8\n",
    "else:\n",
    "    PARAMS_TRAIN_GENERATOR['batch_size'] = int(128)\n",
    "    PARAMS_VALID_GENERATOR['batch_size'] = int(128)\n",
    "    learning_late = config_params['training']['l_rate']\n",
    "\n",
    "# ---------- Change the subject number (now is 28) according to DB2 ----------\n",
    "SUBJECTS = config_params['dataset'].get('subjects', [i for i in range(1, 41)])\n",
    "if np.min(SUBJECTS) <= 0 or np.max(SUBJECTS) >= 41:\n",
    "    raise AssertionError('Subject IDs should be between 1 and 41 inclusive for DB2. Were given {}\\n'.format(SUBJECTS))\n",
    "\n",
    "PARAMS_TRAIN_GENERATOR.pop('input_directory', '')\n",
    "PARAMS_VALID_GENERATOR.pop('input_directory', '')\n",
    "\n",
    "#MODEL = getNetwork(config_params['model']['name'])\n",
    "\n",
    "mean_train, mean_test, mean_test_3, mean_test_5 = [], [], [], []\n",
    "mean_cm = []\n",
    "mean_train_loss, mean_test_loss = [], []\n",
    "\n",
    "if config_params['logging']['enable']:\n",
    "    if os.path.isfile(LOGGING_FILE) == False:\n",
    "        with open(LOGGING_FILE, 'w') as f:\n",
    "            f.write(\n",
    "                'TIMESTAMP: {}\\n'\n",
    "                'KERAS: {}\\n'\n",
    "                'TENSORFLOW: {}\\n'\n",
    "                'DATASET: {}\\n'\n",
    "                'TRAIN_GENERATOR: {}\\n'\n",
    "                'VALID_GENERATOR: {}\\n'\n",
    "                'MODEL: {}\\n'\n",
    "                'MODEL_PARAMS: {}\\n'\n",
    "                'TRAIN_PARAMS: {}\\n'.format(\n",
    "                    TIMESTAMP,\n",
    "                    keras.__version__, tf.__version__,\n",
    "                    config_params['dataset']['name'], PARAMS_TRAIN_GENERATOR,\n",
    "                    PARAMS_VALID_GENERATOR,\n",
    "                    config_params['model']['name'], config_params['model']['extra'],\n",
    "                    config_params['training']\n",
    "                )\n",
    "            )\n",
    "            f.write(\n",
    "                'SUBJECT,TRAIN_SHAPE,TEST_SHAPE,TRAIN_LOSS,TRAIN_ACC,TEST_LOSS,TEST_ACC,TEST_TOP_3_ACC,TEST_TOP_5_ACC\\n')\n",
    "\n",
    "print('Subject: {}'.format(target_subject))\n",
    "input_dir = '{}/subject-{:02d}'.format(INPUT_DIRECTORY, target_subject)\n",
    "#print(input_dir)\n",
    "#print(\"PARAMS_TRAIN_GENERATOR\")\n",
    "#print(PARAMS_TRAIN_GENERATOR)\n",
    "\n",
    "train_generator = DataGenerator(input_directory=input_dir, **PARAMS_TRAIN_GENERATOR) #classes = [0,range(13,52)],\n",
    "valid_generator = DataGenerator(input_directory=input_dir, **PARAMS_VALID_GENERATOR)\n",
    "X_test, Y_test, test_reps = valid_generator.get_data()                                  # X test,  Y test\n",
    "\n",
    "# print('Train generator:')\n",
    "# print(train_generator)\n",
    "# print('Test generator:')\n",
    "# print(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc661560-fcda-42c0-8db3-76ee1b2bfc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 07:52:58.068709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:52:58.070414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:52:58.071662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 07:52:58.161791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 07:52:58.193321: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:52:58.194419: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:52:58.195677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 12)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, None, 16)     592         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " separable_conv1d (SeparableCon  (None, None, 16)    320         ['conv1d[0][0]']                 \n",
      " v1D)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 16)          0           ['separable_conv1d[0][0]']       \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            17          ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tcn (TCN)                      (None, None, 32)     35744       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           32          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, None, 128)    49664       ['tcn[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, None, 16)     0           ['separable_conv1d[0][0]',       \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, None, 64)    71488       ['input_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 128)         0           ['bidirectional[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 16)          0           ['multiply[0][0]']               \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 64)          0           ['bidirectional_1[0][0]']        \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 208)          0           ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 208)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " channel_attention (ChannelAtte  (None, 208)         5668        ['dropout[0][0]']                \n",
      " ntion)                                                                                           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 50)           10450       ['channel_attention[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 173,975\n",
      "Trainable params: 173,975\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import optimizers, initializers, regularizers, constraints\n",
    "from keras.layers import *\n",
    "from tcn import TCN\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "class ChannelAttention(Layer):\n",
    "    def __init__(self, ratio = 8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=self.channels // self.ratio,\n",
    "                                           activation='relu',\n",
    "                                           kernel_initializer='he_normal',\n",
    "                                           use_bias=True)\n",
    "        self.dense_output = tf.keras.layers.Dense(units=self.channels,\n",
    "                                                  kernel_initializer='he_normal',\n",
    "                                                  use_bias=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs = tf.expand_dims(inputs, axis=2)\n",
    "        gap = tf.reduce_mean(inputs, axis=[0, 1], keepdims=True)\n",
    "\n",
    "        attention = self.dense(gap)\n",
    "        attention = self.dense_output(attention)\n",
    "        attention = tf.keras.activations.sigmoid(attention)\n",
    "\n",
    "        output = tf.multiply(inputs, attention)\n",
    "\n",
    "        return output\n",
    "\n",
    "def se_block(in_block, ch, ratio=12):\n",
    "    z = GlobalAveragePooling1D()(in_block)\n",
    "    x = Dense(ch // ratio, activation='relu')(z)\n",
    "    x = Dense(ch, activation='sigmoid')(x)\n",
    "    return multiply([in_block, x])\n",
    "\n",
    "\n",
    "\n",
    "columns = 12\n",
    "gestures = 50\n",
    "\n",
    "input_shape = (None, columns)\n",
    "\n",
    "input = Input(shape=input_shape)\n",
    "\n",
    "branch1 = TCN(nb_filters=32, nb_stacks=1, kernel_size=3, return_sequences=True)(input)\n",
    "branch1 = Bidirectional(LSTM(64, return_sequences=True))(branch1)\n",
    "\n",
    "branch2 = Conv1D(16, 3)(input)\n",
    "branch2 = SeparableConv1D(filters=16, kernel_size=3, padding='same', activation='relu')(branch2)\n",
    "branch2 = se_block(branch2, ch=16)\n",
    "\n",
    "branch3 = Bidirectional(TCN(nb_filters=32, nb_stacks=1, kernel_size=3, return_sequences=True))(input)\n",
    "\n",
    "# Flatten the sequences before concatenating\n",
    "branch1_flat = GlobalAveragePooling1D()(branch1)\n",
    "branch2_flat = GlobalAveragePooling1D()(branch2)\n",
    "branch3_flat = GlobalAveragePooling1D()(branch3)\n",
    "# input_flat = GlobalAveragePooling1D()(input)\n",
    "\n",
    "# x = concatenate([tcn1_flat, tcn2_flat, tcn3_flat, input_flat])\n",
    "x = concatenate([branch1_flat, branch2_flat, branch3_flat])\n",
    "x = Dropout(0.2)(x)\n",
    "x = ChannelAttention()(x)\n",
    "output = Dense(50, trainable=True, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input, outputs=output)\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class SavePredictionsCallback(Callback):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.predictions_per_epoch = []\n",
    "        self.true_labels_per_epoch = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        self.predictions_per_epoch.append(y_pred)\n",
    "        self.true_labels_per_epoch.append(self.y_test)\n",
    "        print(f\"Epoch {epoch+1}: saved predictions and true labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019a51bf-e5a2-424d-89f5-e5abd21d1c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 07:52:59.471657: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-04-15 07:53:00.629125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:53:00.630946: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:53:00.632303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 07:53:00.733785: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 07:53:00.770316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:53:00.771390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:53:00.772806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 07:53:01.177270: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 07:53:03.026648: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:53:03.028125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:53:03.029257: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 07:53:03.130198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 07:53:03.166640: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:53:03.167717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:53:03.169078: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 07:53:03.573750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 07:53:05.663133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8906\n",
      "2025-04-15 07:53:05.821750: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-15 07:53:05.822672: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-15 07:53:05.822697: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2025-04-15 07:53:05.823203: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-15 07:53:05.823286: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:317] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2025-04-15 07:53:07.261124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-04-15 07:54:11.519416: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:54:11.521436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:54:11.522692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 07:54:11.613879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 07:54:11.646820: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:54:11.648585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:54:11.649521: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 07:54:14.342443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:54:14.345021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:54:14.346114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-04-15 07:54:14.439556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2025-04-15 07:54:14.471386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-04-15 07:54:14.472385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-04-15 07:54:14.473521: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 507ms/step\n",
      "Epoch 1: saved predictions and true labels\n",
      "40/40 - 76s - loss: 12.8092 - accuracy: 0.0195 - top_3_accuracy: 0.0664 - top_5_accuracy: 0.1078 - val_loss: 3.7637 - val_accuracy: 0.0469 - val_top_3_accuracy: 0.1406 - val_top_5_accuracy: 0.2500 - 76s/epoch - 2s/step\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 1s 442ms/step\n",
      "Epoch 2: saved predictions and true labels\n",
      "40/40 - 59s - loss: 3.9681 - accuracy: 0.0324 - top_3_accuracy: 0.0949 - top_5_accuracy: 0.1559 - val_loss: 3.6593 - val_accuracy: 0.0781 - val_top_3_accuracy: 0.2031 - val_top_5_accuracy: 0.3125 - 59s/epoch - 1s/step\n",
      "2/2 [==============================] - 1s 477ms/step\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "if config_params['training']['optimizer'] == 'adam':\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_late, epsilon=0.001)\n",
    "\n",
    "elif config_params['training']['optimizer'] == 'sgd':\n",
    "    optimizer = optimizers.SGD(learning_rate=learning_late, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', top_3_accuracy, top_5_accuracy])\n",
    "\n",
    "train_callbacks = []\n",
    "\n",
    "lrScheduler = MyLRScheduler(**config_params['training']['l_rate_schedule'])\n",
    "train_callbacks.append(lrScheduler)\n",
    "#print(train_generator)\n",
    "\n",
    "save_predictions_callback = SavePredictionsCallback(X_test, Y_test)\n",
    "\n",
    "history = model.fit(train_generator, epochs=2,\n",
    "                              validation_data=(X_test,Y_test), callbacks=[save_predictions_callback], verbose=2)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "#print(history.history)\n",
    "\n",
    "#acc_list.append(max(history.history['accuracy']))\n",
    "\n",
    "if config_params['model']['save']:\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(MODEL_SAVE_FILE.format(SUBJECT), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(MODEL_WEIGHTS_SAVE_FILE.format(SUBJECT))\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "# Confusion Matrix\n",
    "# C_{i, j} is equal to the number of observations known to be in group i but predicted to be in group j.\n",
    "cnf_matrix_frame = metrics.confusion_matrix(y_test, y_pred)\n",
    "if np.array(mean_cm).shape != cnf_matrix_frame.shape:\n",
    "    mean_cm = cnf_matrix_frame\n",
    "else:\n",
    "    mean_cm += cnf_matrix_frame\n",
    "\n",
    "#dict_keys(['loss', 'accuracy', 'top_3_accuracy', 'top_5_accuracy', 'val_loss', 'val_accuracy', 'val_top_3_accuracy', 'val_top_5_accuracy'])\n",
    "\n",
    "mean_train.append(history.history['accuracy'][-1])\n",
    "mean_test.append(history.history['val_accuracy'][-1])\n",
    "mean_train_loss.append(history.history['loss'][-1])\n",
    "mean_test_loss.append(history.history['val_loss'][-1])\n",
    "mean_test_3.append(history.history['val_top_3_accuracy'][-1])\n",
    "mean_test_5.append(history.history['val_top_5_accuracy'][-1])\n",
    "\n",
    "if config_params['logging']['enable']:\n",
    "    with open(LOGGING_FILE, 'a') as f:\n",
    "        f.write('{},{},{},{},{},{},{},{},{}\\n'.format(SUBJECT, train_generator.__len__() * PARAMS_TRAIN_GENERATOR['batch_size'], valid_generator.__len__(),\n",
    "            mean_train_loss[-1], mean_train[-1], mean_test_loss[-1], mean_test[-1], mean_test_3[-1], mean_test_5[-1]))\n",
    "\n",
    "metrics_dict = {\n",
    "    'mean_cm': mean_cm,\n",
    "    'mean_test': mean_test,\n",
    "    'mean_test_3': mean_test_3,\n",
    "    'mean_test_5': mean_test_5,\n",
    "    'mean_train': mean_train,\n",
    "    'mean_train_loss': mean_train_loss,\n",
    "    'mean_test_loss': mean_test_loss\n",
    "}\n",
    "scipy.io.savemat(METRICS_SAVE_FILE.format(SUBJECT), metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db259d9-7763-4a76-96b5-e2b7982f27be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----subject-------\n",
      "1\n",
      "----accuracy-----\n",
      "0.03242187574505806\n",
      "---val accuracy---\n",
      "0.078125\n",
      "Epoch 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0000    0.0000    0.0000         2\n",
      "           2     0.0000    0.0000    0.0000         2\n",
      "           3     0.0000    0.0000    0.0000         2\n",
      "           4     0.0000    0.0000    0.0000         2\n",
      "           5     0.1667    1.0000    0.2857         2\n",
      "           6     0.0000    0.0000    0.0000         2\n",
      "           7     0.0000    0.0000    0.0000         2\n",
      "           8     0.0000    0.0000    0.0000         2\n",
      "           9     0.0667    0.5000    0.1176         2\n",
      "          10     0.0000    0.0000    0.0000         2\n",
      "          11     0.0000    0.0000    0.0000         2\n",
      "          12     0.0000    0.0000    0.0000         2\n",
      "          13     0.0000    0.0000    0.0000         2\n",
      "          14     0.0000    0.0000    0.0000         2\n",
      "          15     0.0000    0.0000    0.0000         2\n",
      "          16     0.0000    0.0000    0.0000         2\n",
      "          17     0.0000    0.0000    0.0000         2\n",
      "          18     0.0000    0.0000    0.0000         2\n",
      "          19     0.0000    0.0000    0.0000         2\n",
      "          20     0.0000    0.0000    0.0000         2\n",
      "          21     0.0000    0.0000    0.0000         2\n",
      "          22     0.0000    0.0000    0.0000         2\n",
      "          23     0.0000    0.0000    0.0000         2\n",
      "          24     0.0000    0.0000    0.0000         2\n",
      "          25     0.0000    0.0000    0.0000         2\n",
      "          26     0.2000    1.0000    0.3333         2\n",
      "          27     0.0000    0.0000    0.0000         2\n",
      "          28     0.0000    0.0000    0.0000         2\n",
      "          29     0.0000    0.0000    0.0000         2\n",
      "          30     0.0000    0.0000    0.0000         2\n",
      "          31     0.0000    0.0000    0.0000         2\n",
      "          32     0.0000    0.0000    0.0000         2\n",
      "\n",
      "    accuracy                         0.0781        64\n",
      "   macro avg     0.0135    0.0781    0.0230        64\n",
      "weighted avg     0.0135    0.0781    0.0230        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"-----subject-------\")\n",
    "print(target_subject)\n",
    "print(\"----accuracy-----\")\n",
    "print(max(history.history['accuracy']))\n",
    "print(\"---val accuracy---\")\n",
    "print(max(history.history['val_accuracy']))\n",
    "\n",
    "predictions_per_epoch = save_predictions_callback.predictions_per_epoch\n",
    "true_labels_per_epoch = save_predictions_callback.true_labels_per_epoch\n",
    "\n",
    "for epoch, (y_pred, y_true) in enumerate(zip(predictions_per_epoch, true_labels_per_epoch)):\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    if (round(metrics.accuracy_score(y_test, y_pred),4) == round(max(history.history['val_accuracy']),4)):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        # print(\"Predictions:\", y_pred)\n",
    "        # print(\"True Labels:\", y_true)\n",
    "\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# target_subject += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7fd2d1c-60ed-4138-abdc-0c380c7154a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in Y_test: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in Y_test:\", np.unique(np.argmax(Y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cab57-3ca1-428b-a2d5-548dc3b9960b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
